{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaUc43lyr-WS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Clone your repo and cd into it\n",
        "REPO_URL = \"https://github.com/kasundi2002/Deep-Learning-Project.git\"  # <-- put your repo URL\n",
        "!git clone {REPO_URL}\n",
        "repo_dir = REPO_URL.rsplit(\"/\", 1)[-1].replace(\".git\", \"\")\n",
        "%cd /content/{repo_dir}\n",
        "\n",
        "# 2) Fetch all branches\n",
        "!git fetch --all --prune\n",
        "!git branch -a  # (optional) see branches\n",
        "\n",
        "# 3) Checkout the existing 'sathmi' branch\n",
        "!git switch sathmi || git switch -c sathmi --track origin/sathmi\n",
        "\n",
        "# 4) Set your Git identity\n",
        "!git config user.name \"sathmi\"\n",
        "!git config user.email \"sathmi@users.noreply.github.com\"  # replace if you prefer another email\n",
        "\n",
        "# 5) Confirm\n",
        "!git status\n",
        "!git branch --show-current\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky6z1ja9sMcD",
        "outputId": "fef65caa-aaa7-46f5-b756-bf4a4dd41250"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deep-Learning-Project'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 34 (delta 11), reused 26 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (34/34), 23.90 KiB | 5.97 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "/content/Deep-Learning-Project\n",
            "Fetching origin\n",
            "* \u001b[32mmain\u001b[m\n",
            "  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/main\n",
            "  \u001b[31mremotes/origin/devmi\u001b[m\n",
            "  \u001b[31mremotes/origin/kasundi\u001b[m\n",
            "  \u001b[31mremotes/origin/main\u001b[m\n",
            "  \u001b[31mremotes/origin/mihiduni\u001b[m\n",
            "  \u001b[31mremotes/origin/sathmi\u001b[m\n",
            "Branch 'sathmi' set up to track remote branch 'sathmi' from 'origin'.\n",
            "Switched to a new branch 'sathmi'\n",
            "On branch sathmi\n",
            "Your branch is up to date with 'origin/sathmi'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "sathmi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "\n",
        "import tensorflow as tf, numpy as np, random, os\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPU devices:\", tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "SEED = 42\n",
        "tf.random.set_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
        "print(\"Seeds set.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83joqNgZsZ0E",
        "outputId": "0b13e584-655d-4374-9319-0d1aaa18418b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct  7 08:08:21 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "TF version: 2.19.0\n",
            "GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Seeds set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Kaggle CLI and authenticate\n",
        "!pip -q install kaggle\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # This returns a dictionary of uploaded files\n",
        "\n",
        "# Get the actual uploaded filename\n",
        "uploaded_filename = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded file: {uploaded_filename}\")\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv '{uploaded_filename}' ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# sanity check\n",
        "!kaggle --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "XlEVdtt9satY",
        "outputId": "ab411876-9f6b-4983-9e56-b7901c3c46d3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-353cae97-35c9-4f4a-9701-4f3b9169a7b2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-353cae97-35c9-4f4a-9701-4f3b9169a7b2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle (1).json to kaggle (1) (3).json\n",
            "Uploaded file: kaggle (1) (3).json\n",
            "Kaggle API 1.7.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix Kaggle CLI auth (handles missing/renamed kaggle.json)\n",
        "import os, json, glob, shutil\n",
        "from google.colab import files\n",
        "\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "cfg_path = \"/root/.kaggle/kaggle.json\"\n",
        "\n",
        "# If not already present, try to find or ask you to upload it\n",
        "if not os.path.exists(cfg_path):\n",
        "    candidates = glob.glob(\"/content/kaggle*.json\")\n",
        "    if not candidates:\n",
        "        print(\"Please upload your kaggle.json\")\n",
        "        uploaded = files.upload()  # pick kaggle.json\n",
        "        local = next(iter(uploaded.keys()))\n",
        "    else:\n",
        "        local = candidates[0]\n",
        "    shutil.move(local, cfg_path)\n",
        "\n",
        "# Lock down permissions\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# Export env vars so CLI definitely sees them\n",
        "creds = json.load(open(cfg_path))\n",
        "os.environ[\"KAGGLE_USERNAME\"] = creds[\"username\"]\n",
        "os.environ[\"KAGGLE_KEY\"] = creds[\"key\"]\n",
        "print(\"Kaggle configured for user:\", creds[\"username\"])\n",
        "!kaggle --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "0gtCg01Rsiep",
        "outputId": "93d2cfa5-fde1-4f22-9fdb-9e90d40529d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your kaggle.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a9394c3b-1810-4dd2-ad5f-b238c7cdc614\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a9394c3b-1810-4dd2-ad5f-b238c7cdc614\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle (1).json to kaggle (1) (1).json\n",
            "Kaggle configured for user: sathmigunawardane\n",
            "Kaggle API 1.7.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, pandas as pd\n",
        "\n",
        "DATA_DIR = \"/content/data\"\n",
        "\n",
        "# Prefer the canonical (capitalized) dirs if both exist\n",
        "img_dir_1 = os.path.join(DATA_DIR, \"HAM10000_images_part_1\") if os.path.isdir(os.path.join(DATA_DIR, \"HAM10000_images_part_1\")) else os.path.join(DATA_DIR, \"ham10000_images_part_1\")\n",
        "img_dir_2 = os.path.join(DATA_DIR, \"HAM10000_images_part_2\") if os.path.isdir(os.path.join(DATA_DIR, \"HAM10000_images_part_2\")) else os.path.join(DATA_DIR, \"ham10000_images_part_2\")\n",
        "meta_csv  = os.path.join(DATA_DIR, \"HAM10000_metadata.csv\")\n",
        "\n",
        "print(\"IMG DIR 1:\", img_dir_1, \"exists:\", os.path.isdir(img_dir_1))\n",
        "print(\"IMG DIR 2:\", img_dir_2, \"exists:\", os.path.isdir(img_dir_2))\n",
        "print(\"META CSV :\", meta_csv, \"exists:\", os.path.isfile(meta_csv))\n",
        "\n",
        "# quick counts\n",
        "n1 = len(glob.glob(os.path.join(img_dir_1, \"*.jpg\")))\n",
        "n2 = len(glob.glob(os.path.join(img_dir_2, \"*.jpg\")))\n",
        "print(f\"Images part1: {n1}, part2: {n2}, total: {n1+n2}\")\n",
        "\n",
        "# peek metadata\n",
        "meta = pd.read_csv(meta_csv)\n",
        "print(\"Metadata rows:\", len(meta))\n",
        "meta.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "TKl7RnSpskwb",
        "outputId": "f68ec096-c694-4c2e-bc40-de55cfee0484"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMG DIR 1: /content/data/HAM10000_images_part_1 exists: True\n",
            "IMG DIR 2: /content/data/HAM10000_images_part_2 exists: True\n",
            "META CSV : /content/data/HAM10000_metadata.csv exists: True\n",
            "Images part1: 5000, part2: 5015, total: 10015\n",
            "Metadata rows: 10015\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     lesion_id      image_id   dx dx_type   age   sex localization\n",
              "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
              "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
              "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
              "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
              "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d1f4382-4002-43d9-8206-c378c4f00ce1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d1f4382-4002-43d9-8206-c378c4f00ce1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d1f4382-4002-43d9-8206-c378c4f00ce1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d1f4382-4002-43d9-8206-c378c4f00ce1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7b48dc45-015f-45ad-a5ac-b05d2ba29e27\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b48dc45-015f-45ad-a5ac-b05d2ba29e27')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7b48dc45-015f-45ad-a5ac-b05d2ba29e27 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "meta",
              "summary": "{\n  \"name\": \"meta\",\n  \"rows\": 10015,\n  \"fields\": [\n    {\n      \"column\": \"lesion_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7470,\n        \"samples\": [\n          \"HAM_0002743\",\n          \"HAM_0004142\",\n          \"HAM_0003658\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10015,\n        \"samples\": [\n          \"ISIC_0033272\",\n          \"ISIC_0031923\",\n          \"ISIC_0026652\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dx\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"bkl\",\n          \"nv\",\n          \"bcc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dx_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"consensus\",\n          \"follow_up\",\n          \"histo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.96861369249538,\n        \"min\": 0.0,\n        \"max\": 85.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          80.0,\n          75.0,\n          50.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"male\",\n          \"female\",\n          \"unknown\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"localization\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"lower extremity\",\n          \"neck\",\n          \"scalp\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63d0efd5",
        "outputId": "1c494bba-f5b3-46ba-c45b-2360d5ae78f6"
      },
      "source": [
        "# Download + unzip to a fixed location\n",
        "!mkdir -p /content/data\n",
        "!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000 -p /content/data\n",
        "!unzip -q /content/data/skin-cancer-mnist-ham10000.zip -d /content/data\n",
        "\n",
        "# Quick sanity check\n",
        "!ls -lah /content/data | head -n 20"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading skin-cancer-mnist-ham10000.zip to /content/data\n",
            "100% 5.18G/5.20G [02:33<00:02, 10.0MB/s]\n",
            "100% 5.20G/5.20G [02:33<00:00, 36.3MB/s]\n",
            "total 5.4G\n",
            "drwxr-xr-x 6 root root 4.0K Oct  7 08:16 .\n",
            "drwxr-xr-x 1 root root 4.0K Oct  7 08:10 ..\n",
            "drwxr-xr-x 2 root root 156K Oct  7 08:16 ham10000_images_part_1\n",
            "drwxr-xr-x 2 root root 156K Oct  7 08:15 HAM10000_images_part_1\n",
            "drwxr-xr-x 2 root root 164K Oct  7 08:16 ham10000_images_part_2\n",
            "drwxr-xr-x 2 root root 164K Oct  7 08:15 HAM10000_images_part_2\n",
            "-rw-r--r-- 1 root root 551K Oct  6  2019 HAM10000_metadata.csv\n",
            "-rw-r--r-- 1 root root  30M Oct  6  2019 hmnist_28_28_L.csv\n",
            "-rw-r--r-- 1 root root  88M Oct  6  2019 hmnist_28_28_RGB.csv\n",
            "-rw-r--r-- 1 root root 2.5M Oct  6  2019 hmnist_8_8_L.csv\n",
            "-rw-r--r-- 1 root root 7.2M Oct  6  2019 hmnist_8_8_RGB.csv\n",
            "-rw-r--r-- 1 root root 5.2G Oct  6  2019 skin-cancer-mnist-ham10000.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from your repo root\n",
        "!python members/run_mobilenet_v2.py -h\n"
      ],
      "metadata": {
        "id": "UCixIj9Rsnor"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure you're in the repo root\n",
        "%cd /content/Deep-Learning-Project\n",
        "\n",
        "# peek at the first ~120 lines to see argparse / expected flags\n",
        "!sed -n '1,120p' members/run_mobilenet_v2.py\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4z6QqN8sqHs",
        "outputId": "7169b635-c41e-40fe-c7f9-dbdbbb49ace5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Deep-Learning-Project\n",
            "#Sathmi"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile members/run_mobilenet_v2.py\n",
        "#!/usr/bin/env python3\n",
        "import argparse, os, glob\n",
        "import pandas as pd\n",
        "\n",
        "def find_data_dirs(data_dir: str):\n",
        "    cap1 = os.path.join(data_dir, \"HAM10000_images_part_1\")\n",
        "    low1 = os.path.join(data_dir, \"ham10000_images_part_1\")\n",
        "    cap2 = os.path.join(data_dir, \"HAM10000_images_part_2\")\n",
        "    low2 = os.path.join(data_dir, \"ham10000_images_part_2\")\n",
        "    img_dir_1 = cap1 if os.path.isdir(cap1) else low1\n",
        "    img_dir_2 = cap2 if os.path.isdir(cap2) else low2\n",
        "    meta_csv  = os.path.join(data_dir, \"HAM10000_metadata.csv\")\n",
        "    return img_dir_1, img_dir_2, meta_csv\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(description=\"MobileNetV2 runner (HAM10000) — path sanity check\")\n",
        "    ap.add_argument(\"--data_dir\", required=True, help=\"Folder with HAM10000 files\")\n",
        "    ap.add_argument(\"--dry_run\", action=\"store_true\", help=\"Only verify paths and exit\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    img1, img2, meta = find_data_dirs(args.data_dir)\n",
        "\n",
        "    assert os.path.isdir(img1), f\"Images part_1 not found: {img1}\"\n",
        "    assert os.path.isdir(img2), f\"Images part_2 not found: {img2}\"\n",
        "    assert os.path.isfile(meta), f\"Metadata CSV not found: {meta}\"\n",
        "\n",
        "    n1 = len(glob.glob(os.path.join(img1, \"*.jpg\")))\n",
        "    n2 = len(glob.glob(os.path.join(img2, \"*.jpg\")))\n",
        "\n",
        "    print(f\"[OK] Metadata: {meta}\")\n",
        "    print(f\"[OK] Images: part1={img1} ({n1}), part2={img2} ({n2}), total={n1+n2}\")\n",
        "\n",
        "    if args.dry_run:\n",
        "        print(\"[OK] Dry run complete.\")\n",
        "        return\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLCaIIlTssI2",
        "outputId": "4c5ee198-93ce-4bbb-d50f-a97964434851"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting members/run_mobilenet_v2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Deep-Learning-Project\n",
        "!python members/run_mobilenet_v2.py --data_dir /content/data --dry_run\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH6b8tprswxy",
        "outputId": "ed45f410-934d-4e92-913b-98c70c808363"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Deep-Learning-Project\n",
            "[OK] Metadata: /content/data/HAM10000_metadata.csv\n",
            "[OK] Images: part1=/content/data/HAM10000_images_part_1 (5000), part2=/content/data/HAM10000_images_part_2 (5015), total=10015\n",
            "[OK] Dry run complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a members/run_mobilenet_v2.py\n",
        "# --- Split HAM10000 into train/val/test and save CSVs ---\n",
        "def make_splits(data_dir, seed=42, test_size=0.15, val_size=0.15):\n",
        "    import os, glob, json\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.model_selection import GroupShuffleSplit\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "    # read metadata\n",
        "    meta_csv = os.path.join(data_dir, \"HAM10000_metadata.csv\")\n",
        "    meta = pd.read_csv(meta_csv)\n",
        "\n",
        "    # map image_id -> absolute filepath\n",
        "    img1, img2, _ = find_data_dirs(data_dir)\n",
        "    id2path = {}\n",
        "    for d in (img1, img2):\n",
        "        for p in glob.glob(os.path.join(d, \"*.jpg\")):\n",
        "            id2path[os.path.splitext(os.path.basename(p))[0]] = p\n",
        "\n",
        "    meta = meta[meta[\"image_id\"].isin(id2path)].copy()\n",
        "    meta[\"filepath\"] = meta[\"image_id\"].map(id2path)\n",
        "\n",
        "    # labels\n",
        "    classes = sorted(meta[\"dx\"].unique())\n",
        "    class2idx = {c: i for i, c in enumerate(classes)}\n",
        "    meta[\"label_idx\"] = meta[\"dx\"].map(class2idx)\n",
        "\n",
        "    # grouped split to avoid near-duplicates across splits\n",
        "    groups = meta[\"lesion_id\"].fillna(meta[\"image_id\"])\n",
        "    gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
        "    train_idx, test_idx = next(gss.split(meta, groups=groups))\n",
        "    train = meta.iloc[train_idx].reset_index(drop=True)\n",
        "    test  = meta.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "    groups_train = train[\"lesion_id\"].fillna(train[\"image_id\"])\n",
        "    gss2 = GroupShuffleSplit(n_splits=1, test_size=val_size, random_state=seed)\n",
        "    tr_idx, val_idx = next(gss2.split(train, groups=groups_train))\n",
        "    train = train.iloc[tr_idx].reset_index(drop=True)\n",
        "    val   = train.iloc[val_idx].reset_index(drop=True) if False else meta.iloc[val_idx].reset_index(drop=True)  # safety\n",
        "\n",
        "    # class weights for imbalanced classes\n",
        "    cw = compute_class_weight(\"balanced\", classes=np.arange(len(classes)), y=train[\"label_idx\"])\n",
        "    class_weights = {int(i): float(w) for i, w in enumerate(cw)}\n",
        "\n",
        "    # save artifacts\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    train.to_csv(\"results/m3_train_split.csv\", index=False)\n",
        "    val.to_csv(\"results/m3_val_split.csv\", index=False)\n",
        "    test.to_csv(\"results/m3_test_split.csv\", index=False)\n",
        "    with open(\"results/m3_meta.json\", \"w\") as f:\n",
        "        json.dump({\"classes\": classes, \"class2idx\": class2idx, \"class_weights\": class_weights}, f, indent=2)\n",
        "asses, class_weights\n",
        "\n",
        "# extend CLI\n",
        "if __name__ == \"__main__\":  # add after previous main definition\n",
        "    pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_RArwRusy8H",
        "outputId": "c1386cad-8565-4fb8-e732-d50baf905da8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to members/run_mobilenet_v2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Deep-Learning-Project\n",
        "!python members/run_mobilenet_v2.py --data_dir /content/data --prepare_split\n",
        "!ls -lh results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEHYLJ0ts2oN",
        "outputId": "aec0af30-58b8-417d-cf06-9c08f8b36e07"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Deep-Learning-Project\n",
            "2025-10-07 08:33:06.529287: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759825986.548870    7046 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759825986.554786    7046 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759825986.569900    7046 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759825986.569930    7046 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759825986.569934    7046 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759825986.569938    7046 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-07 08:33:09.597619: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1759825989.597786    7046 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "[OK] Saved splits → results/: train=7182, val=1306, test=1527\n",
            "[OK] Classes: ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
            "[OK] Class weights: {0: 4.539823008849558, 1: 2.795640326975477, 2: 1.2954545454545454, 3: 11.152173913043478, 4: 1.2857142857142858, 5: 0.2133499688084841, 6: 10.46938775510204}\n",
            "total 1.1M\n",
            "-rw-r--r-- 1 root root  444 Oct  7 08:33 m3_meta.json\n",
            "-rw-r--r-- 1 root root 168K Oct  7 08:33 m3_test_split.csv\n",
            "-rw-r--r-- 1 root root 788K Oct  7 08:33 m3_train_split.csv\n",
            "-rw-r--r-- 1 root root 143K Oct  7 08:33 m3_val_split.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile members/run_mobilenet_v2.py\n",
        "#!/usr/bin/env python3\n",
        "import argparse, os, glob, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "\n",
        "# ---------------- paths & splits ----------------\n",
        "def find_data_dirs(data_dir: str):\n",
        "    cap1 = os.path.join(data_dir, \"HAM10000_images_part_1\")\n",
        "    low1 = os.path.join(data_dir, \"ham10000_images_part_1\")\n",
        "    cap2 = os.path.join(data_dir, \"HAM10000_images_part_2\")\n",
        "    low2 = os.path.join(data_dir, \"ham10000_images_part_2\")\n",
        "    img_dir_1 = cap1 if os.path.isdir(cap1) else low1\n",
        "    img_dir_2 = cap2 if os.path.isdir(cap2) else low2\n",
        "    meta_csv  = os.path.join(data_dir, \"HAM10000_metadata.csv\")\n",
        "    return img_dir_1, img_dir_2, meta_csv\n",
        "\n",
        "def make_splits(data_dir, seed=42, test_size=0.15, val_size=0.15):\n",
        "    meta_csv = os.path.join(data_dir, \"HAM10000_metadata.csv\")\n",
        "    meta = pd.read_csv(meta_csv)\n",
        "\n",
        "    img1, img2, _ = find_data_dirs(data_dir)\n",
        "    id2path = {}\n",
        "    for d in (img1, img2):\n",
        "        for p in glob.glob(os.path.join(d, \"*.jpg\")):\n",
        "            id2path[os.path.splitext(os.path.basename(p))[0]] = p\n",
        "\n",
        "    meta = meta[meta[\"image_id\"].isin(id2path)].copy()\n",
        "    meta[\"filepath\"] = meta[\"image_id\"].map(id2path)\n",
        "\n",
        "    classes = sorted(meta[\"dx\"].unique())\n",
        "    class2idx = {c:i for i,c in enumerate(classes)}\n",
        "    meta[\"label_idx\"] = meta[\"dx\"].map(class2idx)\n",
        "\n",
        "    groups = meta[\"lesion_id\"].fillna(meta[\"image_id\"])\n",
        "    gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
        "    train_idx, test_idx = next(gss.split(meta, groups=groups))\n",
        "    train_full = meta.iloc[train_idx].reset_index(drop=True)\n",
        "    test = meta.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "    gss2 = GroupShuffleSplit(n_splits=1, test_size=val_size, random_state=seed)\n",
        "    groups_train = train_full[\"lesion_id\"].fillna(train_full[\"image_id\"])\n",
        "    tr_idx, val_idx = next(gss2.split(train_full, groups=groups_train))\n",
        "    train = train_full.iloc[tr_idx].reset_index(drop=True)\n",
        "    val   = train_full.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    cw = compute_class_weight(class_weight=\"balanced\",\n",
        "                              classes=np.arange(len(classes)),\n",
        "                              y=train[\"label_idx\"])\n",
        "    class_weights = {int(i): float(w) for i,w in enumerate(cw)}\n",
        "\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    train.to_csv(\"results/m3_train_split.csv\", index=False)\n",
        "    val.to_csv(\"results/m3_val_split.csv\", index=False)\n",
        "    test.to_csv(\"results/m3_test_split.csv\", index=False)\n",
        "    with open(\"results/m3_meta.json\",\"w\") as f:\n",
        "        json.dump({\"classes\": classes,\n",
        "                   \"class2idx\": class2idx,\n",
        "                   \"class_weights\": class_weights}, f, indent=2)\n",
        "    return train, val, test, classes, class_weights\n",
        "\n",
        "def load_splits_and_meta():\n",
        "    train = pd.read_csv(\"results/m3_train_split.csv\")\n",
        "    val   = pd.read_csv(\"results/m3_val_split.csv\")\n",
        "    test  = pd.read_csv(\"results/m3_test_split.csv\")\n",
        "    with open(\"results/m3_meta.json\") as f:\n",
        "        meta = json.load(f)\n",
        "    classes = meta[\"classes\"]\n",
        "    class_weights = {int(k): float(v) for k,v in meta[\"class_weights\"].items()}\n",
        "    return train, val, test, classes, class_weights\n",
        "\n",
        "# ---------------- tf.data pipeline ----------------\n",
        "IMG_SIZE = 224\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "AUG_STRONG = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "    tf.keras.layers.RandomContrast(0.1),   # stronger aug for MobileNetV2\n",
        "], name=\"aug_strong\")\n",
        "\n",
        "def _decode(path, label_idx, num_classes):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = tf.cast(img, tf.float32)  # keep 0..255; will use MobileNetV2 preprocess in the model\n",
        "    label = tf.one_hot(label_idx, depth=num_classes)\n",
        "    return img, label\n",
        "\n",
        "def make_dataset(df, num_classes, training=True, batch_size=32, strong_aug=True):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((df[\"filepath\"].values, df[\"label_idx\"].values))\n",
        "    if training:\n",
        "        ds = ds.shuffle(len(df), seed=42)\n",
        "    ds = ds.map(lambda p,l: _decode(p,l,num_classes), num_parallel_calls=AUTOTUNE)\n",
        "    if training and strong_aug:\n",
        "        ds = ds.map(lambda x,y: (AUG_STRONG(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# ---------------- CLI ----------------\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(description=\"MobileNetV2 runner (HAM10000)\")\n",
        "    ap.add_argument(\"--data_dir\", required=True, help=\"Folder with HAM10000 files\")\n",
        "    ap.add_argument(\"--dry_run\", action=\"store_true\", help=\"Only verify paths and exit\")\n",
        "    ap.add_argument(\"--prepare_split\", action=\"store_true\", help=\"Create train/val/test CSVs and exit\")\n",
        "    ap.add_argument(\"--ds_check\", action=\"store_true\", help=\"Build tf.data and print one batch shape\")\n",
        "    ap.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    img1, img2, meta = find_data_dirs(args.data_dir)\n",
        "    if not (os.path.isdir(img1) and os.path.isdir(img2) and os.path.isfile(meta)):\n",
        "        raise SystemExit(f\"[ERR] Dataset paths missing.\\nimg1={img1}\\nimg2={img2}\\nmeta={meta}\")\n",
        "\n",
        "    if args.dry_run:\n",
        "        n1 = len(glob.glob(os.path.join(img1, \"*.jpg\")))\n",
        "        n2 = len(glob.glob(os.path.join(img2, \"*.jpg\")))\n",
        "        print(f\"[OK] Metadata: {meta}\")\n",
        "        print(f\"[OK] Images: part1={img1} ({n1}), part2={img2} ({n2}), total={n1+n2}\")\n",
        "        print(\"[OK] Dry run complete.\")\n",
        "        return\n",
        "\n",
        "    if args.prepare_split:\n",
        "        train, val, test, classes, class_weights = make_splits(args.data_dir)\n",
        "        print(f\"[OK] Saved splits → results/: train={len(train)}, val={len(val)}, test={len(test)}\")\n",
        "        print(f\"[OK] Classes: {classes}\")\n",
        "        print(f\"[OK] Class weights: {class_weights}\")\n",
        "        return\n",
        "\n",
        "    if args.ds_check:\n",
        "        train, val, test, classes, class_weights = load_splits_and_meta()\n",
        "        print(f\"[OK] Loaded splits: train={len(train)}, val={len(val)}, test={len(test)}\")\n",
        "        print(f\"[OK] Classes: {classes}\")\n",
        "        tr_ds = make_dataset(train, num_classes=len(classes), training=True, batch_size=args.batch_size, strong_aug=True)\n",
        "        for xb, yb in tr_ds.take(1):\n",
        "            print(\"[OK] One batch shapes:\", xb.shape, yb.shape)\n",
        "        return\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNk4SAF8s7x-",
        "outputId": "51a523dd-ee59-49a7-b63c-af90ae9858bd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting members/run_mobilenet_v2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Deep-Learning-Project\n",
        "!python members/run_mobilenet_v2.py --data_dir /content/data --ds_check --batch_size 32\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW0KoSiLs-55",
        "outputId": "fbe4f96a-8088-4faf-cb82-91766bd17096"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Deep-Learning-Project\n",
            "2025-10-07 08:33:42.816438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759826022.835766    7217 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759826022.841826    7217 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759826022.856280    7217 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759826022.856307    7217 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759826022.856311    7217 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759826022.856315    7217 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-07 08:33:45.854355: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1759826025.854510    7217 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "[OK] Loaded splits: train=7182, val=1306, test=1527\n",
            "[OK] Classes: ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
            "[OK] One batch shapes: (32, 224, 224, 3) (32, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile members/run_mobilenet_v2.py\n",
        "#!/usr/bin/env python3\n",
        "import argparse, os, glob, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# ---------------- paths & splits ----------------\n",
        "def find_data_dirs(data_dir: str):\n",
        "    cap1 = os.path.join(data_dir, \"HAM10000_images_part_1\")\n",
        "    low1 = os.path.join(data_dir, \"ham10000_images_part_1\")\n",
        "    cap2 = os.path.join(data_dir, \"HAM10000_images_part_2\")\n",
        "    low2 = os.path.join(data_dir, \"ham10000_images_part_2\")\n",
        "    img_dir_1 = cap1 if os.path.isdir(cap1) else low1\n",
        "    img_dir_2 = cap2 if os.path.isdir(cap2) else low2\n",
        "    meta_csv  = os.path.join(data_dir, \"HAM10000_metadata.csv\")\n",
        "    return img_dir_1, img_dir_2, meta_csv\n",
        "\n",
        "def make_splits(data_dir, seed=42, test_size=0.15, val_size=0.15):\n",
        "    meta_csv = os.path.join(data_dir, \"HAM10000_metadata.csv\")\n",
        "    meta = pd.read_csv(meta_csv)\n",
        "\n",
        "    img1, img2, _ = find_data_dirs(data_dir)\n",
        "    id2path = {}\n",
        "    for d in (img1, img2):\n",
        "        for p in glob.glob(os.path.join(d, \"*.jpg\")):\n",
        "            id2path[os.path.splitext(os.path.basename(p))[0]] = p\n",
        "\n",
        "    meta = meta[meta[\"image_id\"].isin(id2path)].copy()\n",
        "    meta[\"filepath\"] = meta[\"image_id\"].map(id2path)\n",
        "\n",
        "    classes = sorted(meta[\"dx\"].unique())\n",
        "    class2idx = {c:i for i,c in enumerate(classes)}\n",
        "    meta[\"label_idx\"] = meta[\"dx\"].map(class2idx)\n",
        "\n",
        "    groups = meta[\"lesion_id\"].fillna(meta[\"image_id\"])\n",
        "    gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
        "    train_idx, test_idx = next(gss.split(meta, groups=groups))\n",
        "    train_full = meta.iloc[train_idx].reset_index(drop=True)\n",
        "    test = meta.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "    gss2 = GroupShuffleSplit(n_splits=1, test_size=val_size, random_state=seed)\n",
        "    groups_train = train_full[\"lesion_id\"].fillna(train_full[\"image_id\"])\n",
        "    tr_idx, val_idx = next(gss2.split(train_full, groups=groups_train))\n",
        "    train = train_full.iloc[tr_idx].reset_index(drop=True)\n",
        "    val   = train_full.iloc[val_idx].reset_index_drop=True if False else train_full.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    cw = compute_class_weight(class_weight=\"balanced\",\n",
        "                              classes=np.arange(len(classes)),\n",
        "                              y=train[\"label_idx\"])\n",
        "    class_weights = {int(i): float(w) for i,w in enumerate(cw)}\n",
        "\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    train.to_csv(\"results/m3_train_split.csv\", index=False)\n",
        "    val.to_csv(\"results/m3_val_split.csv\", index=False)\n",
        "    test.to_csv(\"results/m3_test_split.csv\", index=False)\n",
        "    with open(\"results/m3_meta.json\",\"w\") as f:\n",
        "        json.dump({\"classes\": classes,\n",
        "                   \"class2idx\": class2idx,\n",
        "                   \"class_weights\": class_weights}, f, indent=2)\n",
        "    return train, val, test, classes, class_weights\n",
        "\n",
        "def load_splits_and_meta():\n",
        "    train = pd.read_csv(\"results/m3_train_split.csv\")\n",
        "    val   = pd.read_csv(\"results/m3_val_split.csv\")\n",
        "    test  = pd.read_csv(\"results/m3_test_split.csv\")\n",
        "    with open(\"results/m3_meta.json\") as f:\n",
        "        meta = json.load(f)\n",
        "    classes = meta[\"classes\"]\n",
        "    class_weights = {int(k): float(v) for k,v in meta[\"class_weights\"].items()}\n",
        "    return train, val, test, classes, class_weights\n",
        "\n",
        "# ---------------- tf.data pipeline ----------------\n",
        "IMG_SIZE = 224\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "AUG_STRONG = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "    tf.keras.layers.RandomContrast(0.1),   # stronger aug for MobileNetV2\n",
        "], name=\"aug_strong\")\n",
        "\n",
        "def _decode(path, label_idx, num_classes):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    label = tf.one_hot(label_idx, depth=num_classes)\n",
        "    return img, label\n",
        "\n",
        "def make_dataset(df, num_classes, training=True, batch_size=32, strong_aug=True):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((df[\"filepath\"].values, df[\"label_idx\"].values))\n",
        "    if training:\n",
        "        ds = ds.shuffle(len(df), seed=42)\n",
        "    ds = ds.map(lambda p,l: _decode(p,l,num_classes), num_parallel_calls=AUTOTUNE)\n",
        "    if training and strong_aug:\n",
        "        ds = ds.map(lambda x,y: (AUG_STRONG(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# ---------------- model & training ----------------\n",
        "def build_mobilenetv2(num_classes: int):\n",
        "    base = MobileNetV2(include_top=False, weights=\"imagenet\",\n",
        "                       input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    inp = tf.keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = preprocess_input(inp)\n",
        "    x = base(x, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    model = models.Model(inp, out)\n",
        "    return model, base\n",
        "\n",
        "def train_mobilenetv2(data_dir, batch_size, epochs1, epochs2, unfreeze_last, lr1, lr2):\n",
        "    train, val, test, classes, class_weights = load_splits_and_meta()\n",
        "    tr = make_dataset(train, len(classes), training=True,  batch_size=batch_size, strong_aug=True)\n",
        "    va = make_dataset(val,   len(classes), training=False, batch_size=batch_size, strong_aug=False)\n",
        "\n",
        "    model, base = build_mobilenetv2(len(classes))\n",
        "\n",
        "    # Stage 1 — freeze backbone\n",
        "    base.trainable = False\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr1),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")])\n",
        "    os.makedirs(\"weights\", exist_ok=True)\n",
        "    cbs1 = [\n",
        "        tf.keras.callbacks.ModelCheckpoint(\"weights/m3_best_stage1.keras\", monitor=\"val_accuracy\", save_best_only=True),\n",
        "        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "    ]\n",
        "    hist1 = model.fit(tr, validation_data=va, epochs=epochs1, class_weight=class_weights, callbacks=cbs1)\n",
        "\n",
        "    # Stage 2 — unfreeze last N layers\n",
        "    base.trainable = True\n",
        "    for layer in base.layers[:-unfreeze_last]:\n",
        "        layer.trainable = False\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr2),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")])\n",
        "    cbs2 = [\n",
        "        tf.keras.callbacks.ModelCheckpoint(\"weights/m3_best_stage2.keras\", monitor=\"val_accuracy\", save_best_only=True),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.2, min_lr=1e-6),\n",
        "        tf.keras.callbacks.EarlyStopping(patience=6, restore_best_weights=True)\n",
        "    ]\n",
        "    hist2 = model.fit(tr, validation_data=va, epochs=epochs2, class_weight=class_weights, callbacks=cbs2)\n",
        "\n",
        "    # Save final model + history\n",
        "    model.save(\"weights/m3_mobilenetv2_final.keras\")\n",
        "    with open(\"results/m3_train_history.json\",\"w\") as f:\n",
        "        json.dump({\"stage1\": hist1.history, \"stage2\": hist2.history}, f)\n",
        "\n",
        "    print(\"[OK] Training completed. Best weights saved under weights/.\")\n",
        "\n",
        "# ---------------- CLI ----------------\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(description=\"MobileNetV2 runner (HAM10000)\")\n",
        "    ap.add_argument(\"--data_dir\", required=True, help=\"Folder with HAM10000 files\")\n",
        "    ap.add_argument(\"--dry_run\", action=\"store_true\", help=\"Only verify paths and exit\")\n",
        "    ap.add_argument(\"--prepare_split\", action=\"store_true\", help=\"Create train/val/test CSVs and exit\")\n",
        "    ap.add_argument(\"--ds_check\", action=\"store_true\", help=\"Build tf.data and print one batch shape\")\n",
        "    ap.add_argument(\"--train\", action=\"store_true\", help=\"Train MobileNetV2 (2-stage)\")\n",
        "    ap.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    ap.add_argument(\"--epochs1\", type=int, default=10)\n",
        "    ap.add_argument(\"--epochs2\", type=int, default=10)\n",
        "    ap.add_argument(\"--unfreeze_last\", type=int, default=20)\n",
        "    ap.add_argument(\"--lr1\", type=float, default=1e-3)\n",
        "    ap.add_argument(\"--lr2\", type=float, default=1e-4)\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    img1, img2, meta = find_data_dirs(args.data_dir)\n",
        "    if not (os.path.isdir(img1) and os.path.isdir(img2) and os.path.isfile(meta)):\n",
        "        raise SystemExit(f\"[ERR] Dataset paths missing.\\nimg1={img1}\\nimg2={img2}\\nmeta={meta}\")\n",
        "\n",
        "    if args.dry_run:\n",
        "        n1 = len(glob.glob(os.path.join(img1, \"*.jpg\")))\n",
        "        n2 = len(glob.glob(os.path.join(img2, \"*.jpg\")))\n",
        "        print(f\"[OK] Metadata: {meta}\")\n",
        "        print(f\"[OK] Images: part1={img1} ({n1}), part2={img2} ({n2}), total={n1+n2}\")\n",
        "        print(\"[OK] Dry run complete.\")\n",
        "        return\n",
        "\n",
        "    if args.prepare_split:\n",
        "        train, val, test, classes, class_weights = make_splits(args.data_dir)\n",
        "        print(f\"[OK] Saved splits → results/: train={len(train)}, val={len(val)}, test={len(test)}\")\n",
        "        print(f\"[OK] Classes: {classes}\")\n",
        "        print(f\"[OK] Class weights: {class_weights}\")\n",
        "        return\n",
        "\n",
        "    if args.ds_check:\n",
        "        train, val, test, classes, class_weights = load_splits_and_meta()\n",
        "        print(f\"[OK] Loaded splits: train={len(train)}, val={len(val)}, test={len(test)}\")\n",
        "        print(f\"[OK] Classes: {classes}\")\n",
        "        tr_ds = make_dataset(train, num_classes=len(classes), training=True, batch_size=args.batch_size, strong_aug=True)\n",
        "        for xb, yb in tr_ds.take(1):\n",
        "            print(\"[OK] One batch shapes:\", xb.shape, yb.shape)\n",
        "        return\n",
        "\n",
        "    if args.train:\n",
        "        train_mobilenetv2(args.data_dir, args.batch_size, args.epochs1, args.epochs2, args.unfreeze_last, args.lr1, args.lr2)\n",
        "        return\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBki6ASJtCze",
        "outputId": "6a0bf55c-a28e-468d-d855-c42443406bf2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting members/run_mobilenet_v2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Deep-Learning-Project\n",
        "!python members/run_mobilenet_v2.py \\\n",
        "  --data_dir /content/data \\\n",
        "  --train \\\n",
        "  --batch_size 32 \\\n",
        "  --epochs1 3 \\\n",
        "  --epochs2 3 \\\n",
        "  --unfreeze_last 20 \\\n",
        "  --lr1 1e-3 \\\n",
        "  --lr2 1e-4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NIAOkOhtFMD",
        "outputId": "a3045772-63ae-42d6-8121-111b6f8e0bbf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Deep-Learning-Project\n",
            "2025-10-07 08:34:04.340750: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759826044.360399    7362 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759826044.366305    7362 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759826044.381028    7362 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759826044.381060    7362 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759826044.381064    7362 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759826044.381068    7362 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-07 08:34:07.395233: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1759826047.395387    7362 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/3\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1759826056.309635    7397 service.cc:152] XLA service 0x79b700011090 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1759826056.309697    7397 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1759826058.179431    7397 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2025-10-07 08:34:28.298989: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-10-07 08:34:28.434731: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "I0000 00:00:1759826070.976155    7397 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m224/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - accuracy: 0.4158 - auc: 0.7756 - loss: 1.83762025-10-07 08:36:22.309387: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-10-07 08:36:22.450690: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.4159 - auc: 0.7757 - loss: 1.83672025-10-07 08:36:45.024024: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-10-07 08:36:45.160252: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 610ms/step - accuracy: 0.4160 - auc: 0.7758 - loss: 1.8358 - val_accuracy: 0.5850 - val_auc: 0.9023 - val_loss: 1.1081\n",
            "Epoch 2/3\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 466ms/step - accuracy: 0.5282 - auc: 0.8634 - loss: 1.2321 - val_accuracy: 0.5697 - val_auc: 0.8930 - val_loss: 1.1218\n",
            "Epoch 3/3\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 476ms/step - accuracy: 0.5504 - auc: 0.8779 - loss: 1.1890 - val_accuracy: 0.5697 - val_auc: 0.8934 - val_loss: 1.1190\n",
            "Epoch 1/3\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 538ms/step - accuracy: 0.5122 - auc: 0.8546 - loss: 1.4532 - val_accuracy: 0.7289 - val_auc: 0.9458 - val_loss: 0.8767 - learning_rate: 1.0000e-04\n",
            "Epoch 2/3\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 501ms/step - accuracy: 0.6117 - auc: 0.9095 - loss: 0.9384 - val_accuracy: 0.7198 - val_auc: 0.9477 - val_loss: 0.8214 - learning_rate: 1.0000e-04\n",
            "Epoch 3/3\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 480ms/step - accuracy: 0.6569 - auc: 0.9286 - loss: 0.8226 - val_accuracy: 0.6907 - val_auc: 0.9420 - val_loss: 0.8655 - learning_rate: 1.0000e-04\n",
            "[OK] Training completed. Best weights saved under weights/.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile members/run_mobilenet_v2.py\n",
        "#!/usr/bin/env python3\n",
        "import argparse, os, glob, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------- paths & splits ----------------\n",
        "def find_data_dirs(data_dir: str):\n",
        "    cap1 = os.path.join(data_dir, \"HAM10000_images_part_1\")\n",
        "    low1 = os.path.join(data_dir, \"ham10000_images_part_1\")\n",
        "    cap2 = os.path.join(data_dir, \"HAM10000_images_part_2\")\n",
        "    low2 = os.path.join(data_dir, \"ham10000_images_part_2\")\n",
        "    img_dir_1 = cap1 if os.path.isdir(cap1) else low1\n",
        "    img_dir_2 = cap2 if os.path.isdir(cap2) else low2\n",
        "    meta_csv  = os.path.join(data_dir, \"HAM10000_metadata.csv\")\n",
        "    return img_dir_1, img_dir_2, meta_csv\n",
        "\n",
        "def make_splits(data_dir, seed=42, test_size=0.15, val_size=0.15):\n",
        "    meta_csv = os.path.join(data_dir, \"HAM10000_metadata.csv\")\n",
        "    meta = pd.read_csv(meta_csv)\n",
        "\n",
        "    img1, img2, _ = find_data_dirs(data_dir)\n",
        "    id2path = {}\n",
        "    for d in (img1, img2):\n",
        "        for p in glob.glob(os.path.join(d, \"*.jpg\")):\n",
        "            id2path[os.path.splitext(os.path.basename(p))[0]] = p\n",
        "\n",
        "    meta = meta[meta[\"image_id\"].isin(id2path)].copy()\n",
        "    meta[\"filepath\"] = meta[\"image_id\"].map(id2path)\n",
        "\n",
        "    classes = sorted(meta[\"dx\"].unique())\n",
        "    class2idx = {c:i for i,c in enumerate(classes)}\n",
        "    meta[\"label_idx\"] = meta[\"dx\"].map(class2idx)\n",
        "\n",
        "    groups = meta[\"lesion_id\"].fillna(meta[\"image_id\"])\n",
        "    gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
        "    train_idx, test_idx = next(gss.split(meta, groups=groups))\n",
        "    train_full = meta.iloc[train_idx].reset_index(drop=True)\n",
        "    test = meta.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "    gss2 = GroupShuffleSplit(n_splits=1, test_size=val_size, random_state=seed)\n",
        "    groups_train = train_full[\"lesion_id\"].fillna(train_full[\"image_id\"])\n",
        "    tr_idx, val_idx = next(gss2.split(train_full, groups=groups_train))\n",
        "    train = train_full.iloc[tr_idx].reset_index(drop=True)\n",
        "    val   = train_full.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    cw = compute_class_weight(class_weight=\"balanced\",\n",
        "                              classes=np.arange(len(classes)),\n",
        "                              y=train[\"label_idx\"])\n",
        "    class_weights = {int(i): float(w) for i,w in enumerate(cw)}\n",
        "\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    train.to_csv(\"results/m3_train_split.csv\", index=False)\n",
        "    val.to_csv(\"results/m3_val_split.csv\", index=False)\n",
        "    test.to_csv(\"results/m3_test_split.csv\", index=False)\n",
        "    with open(\"results/m3_meta.json\",\"w\") as f:\n",
        "        json.dump({\"classes\": classes,\n",
        "                   \"class2idx\": class2idx,\n",
        "                   \"class_weights\": class_weights}, f, indent=2)\n",
        "    return train, val, test, classes, class_weights\n",
        "\n",
        "def load_splits_and_meta():\n",
        "    train = pd.read_csv(\"results/m3_train_split.csv\")\n",
        "    val   = pd.read_csv(\"results/m3_val_split.csv\")\n",
        "    test  = pd.read_csv(\"results/m3_test_split.csv\")\n",
        "    with open(\"results/m3_meta.json\") as f:\n",
        "        meta = json.load(f)\n",
        "    classes = meta[\"classes\"]\n",
        "    class_weights = {int(k): float(v) for k,v in meta[\"class_weights\"].items()}\n",
        "    return train, val, test, classes, class_weights\n",
        "\n",
        "# ---------------- tf.data pipeline ----------------\n",
        "IMG_SIZE = 224\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "AUG_STRONG = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "    tf.keras.layers.RandomContrast(0.1),   # stronger aug for MobileNetV2\n",
        "], name=\"aug_strong\")\n",
        "\n",
        "def _decode(path, label_idx, num_classes):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    label = tf.one_hot(label_idx, depth=num_classes)\n",
        "    return img, label\n",
        "\n",
        "def make_dataset(df, num_classes, training=True, batch_size=32, strong_aug=True):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((df[\"filepath\"].values, df[\"label_idx\"].values))\n",
        "    if training:\n",
        "        ds = ds.shuffle(len(df), seed=42)\n",
        "    ds = ds.map(lambda p,l: _decode(p,l,num_classes), num_parallel_calls=AUTOTUNE)\n",
        "    if training and strong_aug:\n",
        "        ds = ds.map(lambda x,y: (AUG_STRONG(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# ---------------- model & training ----------------\n",
        "def build_mobilenetv2(num_classes: int):\n",
        "    base = MobileNetV2(include_top=False, weights=\"imagenet\",\n",
        "                       input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    inp = tf.keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = preprocess_input(inp)\n",
        "    x = base(x, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    model = models.Model(inp, out)\n",
        "    return model, base\n",
        "\n",
        "def train_mobilenetv2(data_dir, batch_size, epochs1, epochs2, unfreeze_last, lr1, lr2):\n",
        "    train, val, test, classes, class_weights = load_splits_and_meta()\n",
        "    tr = make_dataset(train, len(classes), training=True,  batch_size=batch_size, strong_aug=True)\n",
        "    va = make_dataset(val,   len(classes), training=False, batch_size=batch_size, strong_aug=False)\n",
        "\n",
        "    model, base = build_mobilenetv2(len(classes))\n",
        "\n",
        "    # Stage 1 — freeze backbone\n",
        "    base.trainable = False\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr1),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")])\n",
        "    os.makedirs(\"weights\", exist_ok=True)\n",
        "    cbs1 = [\n",
        "        tf.keras.callbacks.ModelCheckpoint(\"weights/m3_best_stage1.keras\", monitor=\"val_accuracy\", save_best_only=True),\n",
        "        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "    ]\n",
        "    hist1 = model.fit(tr, validation_data=va, epochs=epochs1, class_weight=class_weights, callbacks=cbs1)\n",
        "\n",
        "    # Stage 2 — unfreeze last N layers\n",
        "    base.trainable = True\n",
        "    for layer in base.layers[:-unfreeze_last]:\n",
        "        layer.trainable = False\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr2),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")])\n",
        "    cbs2 = [\n",
        "        tf.keras.callbacks.ModelCheckpoint(\"weights/m3_best_stage2.keras\", monitor=\"val_accuracy\", save_best_only=True),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.2, min_lr=1e-6),\n",
        "        tf.keras.callbacks.EarlyStopping(patience=6, restore_best_weights=True)\n",
        "    ]\n",
        "    hist2 = model.fit(tr, validation_data=va, epochs=epochs2, class_weight=class_weights, callbacks=cbs2)\n",
        "\n",
        "    # Save final model + history\n",
        "    model.save(\"weights/m3_mobilenetv2_final.keras\")\n",
        "    with open(\"results/m3_train_history.json\",\"w\") as f:\n",
        "        json.dump({\"stage1\": hist1.history, \"stage2\": hist2.history}, f)\n",
        "\n",
        "    print(\"[OK] Training completed. Best weights saved under weights/.\")\n",
        "\n",
        "# ---------------- evaluation ----------------\n",
        "def evaluate_mobilenetv2(batch_size):\n",
        "    train, val, test, classes, _ = load_splits_and_meta()\n",
        "    te = make_dataset(test, len(classes), training=False, batch_size=batch_size, strong_aug=False)\n",
        "\n",
        "    model, _ = build_mobilenetv2(len(classes))\n",
        "    # pick best weights available\n",
        "    ckpts = [\"weights/m3_best_stage2.keras\", \"weights/m3_best_stage1.keras\", \"weights/m3_mobilenetv2_final.keras\"]\n",
        "    ckpt = next((p for p in ckpts if os.path.exists(p)), None)\n",
        "    if not ckpt:\n",
        "        raise SystemExit(\"[ERR] No weights found. Train first.\")\n",
        "    model.load_weights(ckpt)\n",
        "    print(f\"[OK] Loaded weights: {ckpt}\")\n",
        "\n",
        "    probs = model.predict(te, verbose=0)\n",
        "    y_pred = probs.argmax(1)\n",
        "    y_true = test[\"label_idx\"].values\n",
        "\n",
        "    report = classification_report(y_true, y_pred, target_names=classes, digits=4, output_dict=True)\n",
        "    # print nicely\n",
        "    print(json.dumps(report, indent=2))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(classes))))\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.imshow(cm, interpolation=\"nearest\")\n",
        "    plt.title(\"Confusion Matrix — MobileNetV2 on HAM10000\")\n",
        "    plt.xticks(range(len(classes)), classes, rotation=45, ha=\"right\")\n",
        "    plt.yticks(range(len(classes)), classes)\n",
        "    for i in range(len(classes)):\n",
        "        for j in range(len(classes)):\n",
        "            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"results/m3_confusion_matrix.png\", dpi=150)\n",
        "    print(\"[OK] Saved confusion matrix → results/m3_confusion_matrix.png\")\n",
        "\n",
        "    # also save the raw report\n",
        "    with open(\"results/m3_test_report.json\",\"w\") as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "    print(\"[OK] Saved test report → results/m3_test_report.json\")\n",
        "\n",
        "# ---------------- CLI ----------------\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(description=\"MobileNetV2 runner (HAM10000)\")\n",
        "    ap.add_argument(\"--data_dir\", required=True, help=\"Folder with HAM10000 files\")\n",
        "    ap.add_argument(\"--dry_run\", action=\"store_true\", help=\"Only verify paths and exit\")\n",
        "    ap.add_argument(\"--prepare_split\", action=\"store_true\", help=\"Create train/val/test CSVs and exit\")\n",
        "    ap.add_argument(\"--ds_check\", action=\"store_true\", help=\"Build tf.data and print one batch shape\")\n",
        "    ap.add_argument(\"--train\", action=\"store_true\", help=\"Train MobileNetV2 (2-stage)\")\n",
        "    ap.add_argument(\"--eval\", action=\"store_true\", help=\"Evaluate on test set and save confusion matrix\")\n",
        "    ap.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    ap.add_argument(\"--epochs1\", type=int, default=10)\n",
        "    ap.add_argument(\"--epochs2\", type=int, default=10)\n",
        "    ap.add_argument(\"--unfreeze_last\", type=int, default=20)\n",
        "    ap.add_argument(\"--lr1\", type=float, default=1e-3)\n",
        "    ap.add_argument(\"--lr2\", type=float, default=1e-4)\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    img1, img2, meta = find_data_dirs(args.data_dir)\n",
        "    if not (os.path.isdir(img1) and os.path.isdir(img2) and os.path.isfile(meta)):\n",
        "        raise SystemExit(f\"[ERR] Dataset paths missing.\\nimg1={img1}\\nimg2={img2}\\nmeta={meta}\")\n",
        "\n",
        "    if args.dry_run:\n",
        "        n1 = len(glob.glob(os.path.join(img1, \"*.jpg\")))\n",
        "        n2 = len(glob.glob(os.path.join(img2, \"*.jpg\")))\n",
        "        print(f\"[OK] Metadata: {meta}\")\n",
        "        print(f\"[OK] Images: part1={img1} ({n1}), part2={img2} ({n2}), total={n1+n2}\")\n",
        "        print(\"[OK] Dry run complete.\")\n",
        "        return\n",
        "\n",
        "    if args.prepare_split:\n",
        "        train, val, test, classes, class_weights = make_splits(args.data_dir)\n",
        "        print(f\"[OK] Saved splits → results/: train={len(train)}, val={len(val)}, test={len(test)}\")\n",
        "        print(f\"[OK] Classes: {classes}\")\n",
        "        print(f\"[OK] Class weights: {class_weights}\")\n",
        "        return\n",
        "\n",
        "    if args.ds_check:\n",
        "        train, val, test, classes, class_weights = load_splits_and_meta()\n",
        "        print(f\"[OK] Loaded splits: train={len(train)}, val={len(val)}, test={len(test)}\")\n",
        "        print(f\"[OK] Classes: {classes}\")\n",
        "        tr_ds = make_dataset(train, num_classes=len(classes), training=True, batch_size=args.batch_size, strong_aug=True)\n",
        "        for xb, yb in tr_ds.take(1):\n",
        "            print(\"[OK] One batch shapes:\", xb.shape, yb.shape)\n",
        "        return\n",
        "\n",
        "    if args.train:\n",
        "        train_mobilenetv2(args.data_dir, args.batch_size, args.epochs1, args.epochs2, args.unfreeze_last, args.lr1, args.lr2)\n",
        "        return\n",
        "\n",
        "    if args.eval:\n",
        "        evaluate_mobilenetv2(args.batch_size)\n",
        "        return\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlwlQuJttHZ1",
        "outputId": "46f36d4e-7c0e-4349-bed3-e5b87afc1711"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting members/run_mobilenet_v2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Deep-Learning-Project\n",
        "!python members/run_mobilenet_v2.py --data_dir /content/data --eval --batch_size 32\n",
        "\n",
        "# (optional) preview the confusion matrix image in Colab\n",
        "from IPython.display import Image, display\n",
        "display(Image(\"results/m3_confusion_matrix.png\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i-jeQGpMtJzo",
        "outputId": "e8ac3e08-48d3-4c66-91b9-e5ab7d437bd5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Deep-Learning-Project\n",
            "2025-10-07 08:47:23.994297: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759826844.015051   10917 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759826844.021331   10917 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759826844.036794   10917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759826844.036824   10917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759826844.036828   10917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759826844.036831   10917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-07 08:47:27.075520: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1759826847.075697   10917 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "[OK] Loaded weights: weights/m3_best_stage2.keras\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1759826851.079679   10957 service.cc:152] XLA service 0x7b1f9810ef80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1759826851.079717   10957 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1759826851.625003   10957 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2025-10-07 08:47:38.952325: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-10-07 08:47:39.088407: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "I0000 00:00:1759826860.561148   10957 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "2025-10-07 08:47:58.458478: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-10-07 08:47:58.597636: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-10-07 08:47:58.736037: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "{\n",
            "  \"akiec\": {\n",
            "    \"precision\": 0.5925925925925926,\n",
            "    \"recall\": 0.3333333333333333,\n",
            "    \"f1-score\": 0.4266666666666667,\n",
            "    \"support\": 48.0\n",
            "  },\n",
            "  \"bcc\": {\n",
            "    \"precision\": 0.3114754098360656,\n",
            "    \"recall\": 0.5757575757575758,\n",
            "    \"f1-score\": 0.40425531914893614,\n",
            "    \"support\": 66.0\n",
            "  },\n",
            "  \"bkl\": {\n",
            "    \"precision\": 0.6410256410256411,\n",
            "    \"recall\": 0.14534883720930233,\n",
            "    \"f1-score\": 0.23696682464454977,\n",
            "    \"support\": 172.0\n",
            "  },\n",
            "  \"df\": {\n",
            "    \"precision\": 0.0,\n",
            "    \"recall\": 0.0,\n",
            "    \"f1-score\": 0.0,\n",
            "    \"support\": 10.0\n",
            "  },\n",
            "  \"mel\": {\n",
            "    \"precision\": 0.4603174603174603,\n",
            "    \"recall\": 0.15591397849462366,\n",
            "    \"f1-score\": 0.23293172690763053,\n",
            "    \"support\": 186.0\n",
            "  },\n",
            "  \"nv\": {\n",
            "    \"precision\": 0.7945544554455446,\n",
            "    \"recall\": 0.9478346456692913,\n",
            "    \"f1-score\": 0.8644524236983842,\n",
            "    \"support\": 1016.0\n",
            "  },\n",
            "  \"vasc\": {\n",
            "    \"precision\": 0.5576923076923077,\n",
            "    \"recall\": 1.0,\n",
            "    \"f1-score\": 0.7160493827160493,\n",
            "    \"support\": 29.0\n",
            "  },\n",
            "  \"accuracy\": 0.7203667321545514,\n",
            "  \"macro avg\": {\n",
            "    \"precision\": 0.47966540955851605,\n",
            "    \"recall\": 0.4511697672091609,\n",
            "    \"f1-score\": 0.41161747768317386,\n",
            "    \"support\": 1527.0\n",
            "  },\n",
            "  \"weighted avg\": {\n",
            "    \"precision\": 0.6996186529304733,\n",
            "    \"recall\": 0.7203667321545514,\n",
            "    \"f1-score\": 0.6747174464203244,\n",
            "    \"support\": 1527.0\n",
            "  }\n",
            "}\n",
            "[OK] Saved confusion matrix → results/m3_confusion_matrix.png\n",
            "[OK] Saved test report → results/m3_test_report.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Deep-Learning-Project\n",
        "\n",
        "import json, csv, os, time\n",
        "\n",
        "report_path = \"results/m3_test_report.json\"\n",
        "with open(report_path) as f:\n",
        "    rep = json.load(f)\n",
        "\n",
        "row = [\n",
        "    \"M3_MobileNetV2_strongAug\",           # run name\n",
        "    float(rep[\"accuracy\"]),               # overall accuracy\n",
        "    float(rep[\"macro avg\"][\"precision\"]),\n",
        "    float(rep[\"macro avg\"][\"recall\"]),\n",
        "    float(rep[\"macro avg\"][\"f1-score\"]),\n",
        "    time.strftime(\"%Y-%m-%d %H:%M\")\n",
        "]\n",
        "\n",
        "csv_path = \"results/summary.csv\"\n",
        "if not os.path.exists(csv_path):\n",
        "    with open(csv_path, \"w\", newline=\"\") as f:\n",
        "        csv.writer(f).writerow(\n",
        "            [\"run\",\"accuracy\",\"macro_precision\",\"macro_recall\",\"macro_f1\",\"timestamp\"]\n",
        "        )\n",
        "\n",
        "with open(csv_path, \"a\", newline=\"\") as f:\n",
        "    csv.writer(f).writerow(row)\n",
        "\n",
        "print(\"Wrote:\", csv_path)\n",
        "!tail -n +1 results/summary.csv | sed -n '1,20p'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvI2N75TtM8i",
        "outputId": "bb194b7f-5134-4d2d-98fb-8aad8a251620"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Deep-Learning-Project\n",
            "Wrote: results/summary.csv\n",
            "run,accuracy,macro_precision,macro_recall,macro_f1,timestamp\r\n",
            "M3_MobileNetV2_strongAug,0.7203667321545514,0.47966540955851605,0.4511697672091609,0.41161747768317386,2025-10-07 08:50\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "token = getpass(\"GitHub Personal Access Token (will not be saved): \")\n",
        "!git remote set-url origin https://{token}@github.com/<org-or-user>/<repo>.git\n",
        "# later, after you add files:\n",
        "# !git add -A && git commit -m \"M3: MobileNetV2 baseline\" && git push -u origin model-m3-mobilenetv2\n"
      ],
      "metadata": {
        "id": "wKaiYaKZtQ6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Deep-Learning-Project\n",
        "\n",
        "# 1) Create/update .gitignore (avoid huge/local stuff)\n",
        "gitignore = \"\"\"\\\n",
        "__pycache__/\n",
        ".ipynb_checkpoints/\n",
        ".DS_Store\n",
        "\n",
        "# Local-only paths/files\n",
        "/content/\n",
        "data/\n",
        "*.zip\n",
        ".kaggle/\n",
        "weights/\n",
        "\"\"\"\n",
        "with open(\".gitignore\",\"w\") as f:\n",
        "    f.write(gitignore)\n",
        "\n",
        "# 2) Stage code + small result artifacts\n",
        "!git add members/run_mobilenet_v2.py .gitignore\n",
        "!git add results/m3_*.csv results/m3_*.json results/*.png\n",
        "\n",
        "# 3) Commit\n",
        "!git commit -m \"M3: MobileNetV2 (HAM10000) — splits, strong aug tf.data, 2-stage fine-tune, eval + logs\"\n",
        "\n",
        "# 4) Push (enter your GitHub PAT when asked; it won't be saved)\n",
        "from getpass import getpass\n",
        "token = getpass(\"GitHub token (repo scope): \")\n",
        "\n",
        "import subprocess, shlex\n",
        "origin = subprocess.check_output(shlex.split(\"git config --get remote.origin.url\")).decode().strip()\n",
        "\n",
        "# Rebuild remote URL with token (handles https and git@ forms)\n",
        "if origin.startswith(\"https://\"):\n",
        "    secure_origin = origin.replace(\"https://\", f\"https://{token}@\")\n",
        "elif origin.startswith(\"http://\"):\n",
        "    secure_origin = origin.replace(\"http://\", f\"http://{token}@\")\n",
        "else:\n",
        "    # e.g. git@github.com:org/repo.git -> https://github.com/org/repo.git\n",
        "    path = origin.split(\":\", 1)[-1]\n",
        "    secure_origin = f\"https://{token}@github.com/{path}\"\n",
        "\n",
        "!git remote set-url origin \"{secure_origin}\"\n",
        "!git push -u origin sathmi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "oigaRcpPtRQy",
        "outputId": "0ba8bec8-f9e8-4a57-9e72-0a09de2e6d06"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-2441833265.py, line 37)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2441833265.py\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    rm 'kaggle (1) (1).json' 'kaggle (1) (2).json' 'kaggle (1).json'\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}