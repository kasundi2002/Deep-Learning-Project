{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbFv-2DSZ_Hx",
        "outputId": "cd1f7950-245b-4f31-93b0-c3f8ba1e4ceb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Check GPU\n",
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Npv_otULaBW2"
      },
      "outputs": [],
      "source": [
        "# Basic deps for the split script + training\n",
        "!pip -q install pandas scikit-learn tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-vYKwCeaEBZ",
        "outputId": "fa806d25-5218-408e-d4c0-5139daa25856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#1) Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na1Idn9AaMmI",
        "outputId": "bf8573c0-e874-4eb0-cca6-abee81442586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Local RAW_DIR: total 2.6G\n",
            "-rw------- 1 root root 1.3G Sep 29 15:20 HAM10000_images_part_1.zip\n",
            "-rw------- 1 root root 1.4G Sep 29 15:18 HAM10000_images_part_2.zip\n",
            "-rw------- 1 root root 551K Oct  6  2019 HAM10000_metadata.csv\n"
          ]
        }
      ],
      "source": [
        "#2) Define paths to your files in root of My Drive and copy to fast local SSD\n",
        "# Paths on Drive (root)\n",
        "ZIP1 = \"/content/drive/MyDrive/HAM10000_images_part_1.zip\"\n",
        "ZIP2 = \"/content/drive/MyDrive/HAM10000_images_part_2.zip\"\n",
        "META = \"/content/drive/MyDrive/HAM10000_metadata.csv\"\n",
        "\n",
        "# Local working area on Colab SSD\n",
        "WORK     = \"/content/work\"\n",
        "RAW_DIR  = f\"{WORK}/raw\"\n",
        "EXTRACT  = f\"{WORK}/ham10000_extracted\"\n",
        "DATA_DIR = f\"{WORK}/data\"\n",
        "\n",
        "import os, subprocess, pathlib\n",
        "os.makedirs(RAW_DIR, exist_ok=True)\n",
        "os.makedirs(EXTRACT, exist_ok=True)\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "# Copy only if missing (fast on later sessions)\n",
        "print(subprocess.getoutput(f'rsync -ah --ignore-existing \"{ZIP1}\" \"{ZIP2}\" \"{META}\" \"{RAW_DIR}/\"'))\n",
        "print(\"Local RAW_DIR:\", subprocess.getoutput(f'ls -lh \"{RAW_DIR}\"'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wLW-i61aKxl",
        "outputId": "38d96317-d9d2-40b6-cbbc-6b398ae9bd99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 328K\n",
            "drwxr-xr-x 2 root root 152K Sep 29 20:38 HAM10000_images_part_1\n",
            "drwxrwxrwx 2 root root 168K Sep 29 15:08 HAM10000_images_part_2\n"
          ]
        }
      ],
      "source": [
        "#3) Unzip locally (NOT to Drive)\n",
        "!mkdir -p /content/work/ham10000_extracted\n",
        "!unzip -q /content/work/raw/HAM10000_images_part_1.zip -d /content/work/ham10000_extracted/\n",
        "!unzip -q /content/work/raw/HAM10000_images_part_2.zip -d /content/work/ham10000_extracted/\n",
        "!ls -lh /content/work/ham10000_extracted | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5G4_9Jqme8eS"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0TS6xHzaWm0",
        "outputId": "630d0e89-fb7e-4d10-f421-7305cf1b37bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing /content/scripts/split_ham10000.py\n"
          ]
        }
      ],
      "source": [
        "# #4) Create the split script and run it (makes train/val/test)\n",
        "# %%writefile /content/scripts/split_ham10000.py\n",
        "# #!/usr/bin/env python3\n",
        "# import argparse, os, shutil, zipfile\n",
        "# from pathlib import Path\n",
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# def unzip_if_needed(zip_path: Path, imgs_dir: Path):\n",
        "#     imgs_dir.mkdir(parents=True, exist_ok=True)\n",
        "#     if any(imgs_dir.glob(\"*.jpg\")):\n",
        "#         print(f\"[skip] Images already present in: {imgs_dir}\")\n",
        "#         return\n",
        "#     assert zip_path.exists(), f\"Missing: {zip_path}\"\n",
        "#     print(f\"[unzip] {zip_path.name} → {imgs_dir}\")\n",
        "#     with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "#         z.extractall(imgs_dir)\n",
        "\n",
        "# def build_splits(meta_csv: Path, imgs_dir: Path, train_pct: float, val_pct: float, test_pct: float, seed: int):\n",
        "#     assert abs((train_pct + val_pct + test_pct) - 1.0) < 1e-6, \"Splits must sum to 1.0\"\n",
        "#     meta = pd.read_csv(meta_csv)\n",
        "#     meta[\"image_path\"] = meta[\"image_id\"].apply(lambda x: str(imgs_dir / f\"{x}.jpg\"))\n",
        "#     meta = meta[meta[\"image_path\"].map(lambda p: Path(p).exists())].copy()\n",
        "#     train_df, temp_df = train_test_split(meta, test_size=1.0-train_pct, stratify=meta[\"dx\"], random_state=seed)\n",
        "#     test_rel = test_pct / (val_pct + test_pct)\n",
        "#     val_df, test_df = train_test_split(temp_df, test_size=test_rel, stratify=temp_df[\"dx\"], random_state=seed)\n",
        "#     return train_df, val_df, test_df, sorted(meta[\"dx\"].unique())\n",
        "\n",
        "# def materialize_split(df: pd.DataFrame, split_name: str, out_root: Path):\n",
        "#     base = out_root / split_name; base.mkdir(parents=True, exist_ok=True)\n",
        "#     for cls in sorted(df[\"dx\"].unique()):\n",
        "#         (base / cls).mkdir(parents=True, exist_ok=True)\n",
        "#     for _, r in tqdm(df.iterrows(), total=len(df), desc=f\"{split_name:>5}\", unit=\"img\"):\n",
        "#         src, dst = Path(r[\"image_path\"]), base / r[\"dx\"] / Path(r[\"image_path\"]).name\n",
        "#         if not dst.exists():\n",
        "#             shutil.copy2(src, dst)\n",
        "\n",
        "# def print_counts(data_dir: Path):\n",
        "#     for split in [\"train\",\"val\",\"test\"]:\n",
        "#         base = data_dir / split\n",
        "#         if base.exists():\n",
        "#             counts = {d.name: len(list((base/d).glob(\"*\"))) for d in base.iterdir() if d.is_dir()}\n",
        "#             print(split, counts)\n",
        "\n",
        "# def main():\n",
        "#     p = argparse.ArgumentParser()\n",
        "#     p.add_argument(\"--project_dir\", default=\".\")\n",
        "#     p.add_argument(\"--train\", type=float, default=0.8)\n",
        "#     p.add_argument(\"--val\",   type=float, default=0.1)\n",
        "#     p.add_argument(\"--test\",  type=float, default=0.1)\n",
        "#     p.add_argument(\"--seed\",  type=int, default=42)\n",
        "#     p.add_argument(\"--clean\", action=\"store_true\")\n",
        "#     args = p.parse_args()\n",
        "\n",
        "#     project = Path(args.project_dir).resolve()\n",
        "#     raw_dir  = project / \"raw\"\n",
        "#     data_dir = project / \"data\"\n",
        "#     extract  = project / \"ham10000_extracted\"\n",
        "#     imgs_dir = extract / \"HAM10000_images\"\n",
        "\n",
        "#     part1 = raw_dir / \"HAM10000_images_part_1.zip\"\n",
        "#     part2 = raw_dir / \"HAM10000_images_part_2.zip\"\n",
        "#     meta  = raw_dir / \"HAM10000_metadata.csv\"\n",
        "\n",
        "#     extract.mkdir(parents=True, exist_ok=True); data_dir.mkdir(parents=True, exist_ok=True)\n",
        "#     unzip_if_needed(part1, imgs_dir)\n",
        "#     unzip_if_needed(part2, imgs_dir)\n",
        "\n",
        "#     train_df, val_df, test_df, classes = build_splits(meta, imgs_dir, args.train, args.val, args.test, args.seed)\n",
        "\n",
        "#     if args.clean:\n",
        "#         for s in [\"train\",\"val\",\"test\"]:\n",
        "#             target = data_dir / s\n",
        "#             if target.exists(): shutil.rmtree(target)\n",
        "\n",
        "#     materialize_split(train_df, \"train\", data_dir)\n",
        "#     materialize_split(val_df, \"val\", data_dir)\n",
        "#     materialize_split(test_df, \"test\", data_dir)\n",
        "#     print_counts(data_dir)\n",
        "#     print(\"[done] Data ready at:\", data_dir)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyi02Yv5g6cx",
        "outputId": "82f2f069-4954-4ed5-d7f5-29c0a911b983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/scripts/split_ham10000.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/scripts/split_ham10000.py\n",
        "#!/usr/bin/env python3\n",
        "import argparse, os, shutil, zipfile\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "def unzip_if_needed(zip_path: Path, extract_dir: Path):\n",
        "    extract_dir.mkdir(parents=True, exist_ok=True)\n",
        "    # If any jpgs already exist anywhere under extract_dir, skip\n",
        "    if any(extract_dir.rglob(\"*.jpg\")):\n",
        "        print(f\"[skip] Images already present under: {extract_dir}\")\n",
        "        return\n",
        "    assert zip_path.exists(), f\"Missing: {zip_path}\"\n",
        "    print(f\"[unzip] {zip_path.name} -> {extract_dir}\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "        z.extractall(extract_dir)\n",
        "\n",
        "def index_images(img_root: Path):\n",
        "    \"\"\"\n",
        "    Build a dict: image_id (without .jpg) -> full path\n",
        "    Recurses under img_root to handle both 'HAM10000_images' and '..._part_1/part_2' layouts.\n",
        "    \"\"\"\n",
        "    mapping = {}\n",
        "    for p in img_root.rglob(\"*.jpg\"):\n",
        "        mapping[p.stem] = str(p)\n",
        "    return mapping\n",
        "\n",
        "def build_splits(meta_csv: Path, img_root: Path, train_pct: float, val_pct: float, test_pct: float, seed: int):\n",
        "    assert abs((train_pct + val_pct + test_pct) - 1.0) < 1e-6, \"Splits must sum to 1.0\"\n",
        "    meta = pd.read_csv(meta_csv)\n",
        "    img_map = index_images(img_root)\n",
        "    meta[\"image_path\"] = meta[\"image_id\"].map(img_map)\n",
        "    meta = meta.dropna(subset=[\"image_path\"]).copy()\n",
        "\n",
        "    # quick sanity\n",
        "    print(f\"[info] Found {len(img_map)} jpgs under {img_root}\")\n",
        "    print(f\"[info] Matched rows with metadata: {len(meta)}\")\n",
        "\n",
        "    train_df, temp_df = train_test_split(\n",
        "        meta, test_size=1.0-train_pct, stratify=meta[\"dx\"], random_state=seed\n",
        "    )\n",
        "    test_rel = test_pct / (val_pct + test_pct)\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df, test_size=test_rel, stratify=temp_df[\"dx\"], random_state=seed\n",
        "    )\n",
        "    return train_df, val_df, test_df, sorted(meta[\"dx\"].unique())\n",
        "\n",
        "def materialize_split(df: pd.DataFrame, split_name: str, out_root: Path):\n",
        "    base = out_root / split_name\n",
        "    base.mkdir(parents=True, exist_ok=True)\n",
        "    for cls in sorted(df[\"dx\"].unique()):\n",
        "        (base / cls).mkdir(parents=True, exist_ok=True)\n",
        "    for _, r in tqdm(df.iterrows(), total=len(df), desc=f\"{split_name:>5}\", unit=\"img\"):\n",
        "        src = Path(r[\"image_path\"])\n",
        "        dst = base / r[\"dx\"] / src.name\n",
        "        if not dst.exists():\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "def print_counts(data_dir: Path):\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        base = data_dir / split\n",
        "        if base.exists():\n",
        "            counts = {\n",
        "                d.name: len(list((base / d).glob(\"*\")))\n",
        "                for d in base.iterdir() if d.is_dir()\n",
        "            }\n",
        "            print(split, counts)\n",
        "\n",
        "def main():\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--project_dir\", default=\".\")\n",
        "    p.add_argument(\"--train\", type=float, default=0.8)\n",
        "    p.add_argument(\"--val\",   type=float, default=0.1)\n",
        "    p.add_argument(\"--test\",  type=float, default=0.1)\n",
        "    p.add_argument(\"--seed\",  type=int, default=42)\n",
        "    p.add_argument(\"--clean\", action=\"store_true\")\n",
        "    args = p.parse_args()\n",
        "\n",
        "    project = Path(args.project_dir).resolve()\n",
        "    raw_dir  = project / \"raw\"\n",
        "    data_dir = project / \"data\"\n",
        "    extract  = project / \"ham10000_extracted\"   # we recurse under this folder\n",
        "    imgs_root = extract                         # <-- recursive root\n",
        "\n",
        "    part1 = raw_dir / \"HAM10000_images_part_1.zip\"\n",
        "    part2 = raw_dir / \"HAM10000_images_part_2.zip\"\n",
        "    meta  = raw_dir / \"HAM10000_metadata.csv\"\n",
        "\n",
        "    extract.mkdir(parents=True, exist_ok=True)\n",
        "    data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    unzip_if_needed(part1, extract)\n",
        "    unzip_if_needed(part2, extract)\n",
        "\n",
        "    train_df, val_df, test_df, classes = build_splits(\n",
        "        meta, imgs_root, args.train, args.val, args.test, args.seed\n",
        "    )\n",
        "\n",
        "    if args.clean:\n",
        "        for s in [\"train\", \"val\", \"test\"]:\n",
        "            target = data_dir / s\n",
        "            if target.exists():\n",
        "                shutil.rmtree(target)\n",
        "\n",
        "    materialize_split(train_df, \"train\", data_dir)\n",
        "    materialize_split(val_df, \"val\", data_dir)\n",
        "    materialize_split(test_df, \"test\", data_dir)\n",
        "    print_counts(data_dir)\n",
        "    print(\"[done] Data ready at:\", data_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdcx2xomaawN",
        "outputId": "637bfd82-827f-4ff2-e3cb-2e4118728b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[skip] Images already present under: /content/work/ham10000_extracted\n",
            "[skip] Images already present under: /content/work/ham10000_extracted\n",
            "[info] Found 10015 jpgs under /content/work/ham10000_extracted\n",
            "[info] Matched rows with metadata: 10015\n",
            "train: 100% 8012/8012 [00:15<00:00, 516.57img/s]\n",
            "  val: 100% 1001/1001 [00:02<00:00, 467.86img/s]\n",
            " test: 100% 1002/1002 [00:02<00:00, 435.20img/s]\n",
            "train {'nv': 5364, 'mel': 890, 'bcc': 411, 'vasc': 114, 'akiec': 262, 'df': 92, 'bkl': 879}\n",
            "val {'nv': 670, 'mel': 111, 'bcc': 51, 'vasc': 14, 'akiec': 33, 'df': 12, 'bkl': 110}\n",
            "test {'nv': 671, 'mel': 112, 'bcc': 52, 'vasc': 14, 'akiec': 32, 'df': 11, 'bkl': 110}\n",
            "[done] Data ready at: /content/work/data\n"
          ]
        }
      ],
      "source": [
        "!python /content/scripts/split_ham10000.py \\\n",
        "  --project_dir \"/content/work\" \\\n",
        "  --train 0.8 --val 0.1 --test 0.1 --seed 42 --clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5fOBxPRad-E",
        "outputId": "fc16adf5-d854-4d52-84d5-60a7ed1a71d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train {'akiec': 262, 'bcc': 411, 'bkl': 879, 'df': 92, 'mel': 890, 'nv': 5364, 'vasc': 114}\n",
            "val {'akiec': 33, 'bcc': 51, 'bkl': 110, 'df': 12, 'mel': 111, 'nv': 670, 'vasc': 14}\n",
            "test {'akiec': 32, 'bcc': 52, 'bkl': 110, 'df': 11, 'mel': 112, 'nv': 671, 'vasc': 14}\n"
          ]
        }
      ],
      "source": [
        "#Quick sanity check:\n",
        "import os\n",
        "for split in (\"train\",\"val\",\"test\"):\n",
        "    base = os.path.join(\"/content/work/data\", split)\n",
        "    classes = [d for d in sorted(os.listdir(base)) if os.path.isdir(os.path.join(base,d))]\n",
        "    counts = {c: len(os.listdir(os.path.join(base,c))) for c in classes}\n",
        "    print(split, counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryto_ZVZ0ZSc",
        "outputId": "5924af6b-2d40-4a86-cfc9-5747c6710175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8012 files belonging to 7 classes.\n",
            "Found 1001 files belonging to 7 classes.\n",
            "Found 1002 files belonging to 7 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
            "Epoch 1/2\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 157ms/step - accuracy: 0.2692 - loss: 2.4583 - val_accuracy: 0.3826 - val_loss: 1.6380\n",
            "Epoch 2/2\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 95ms/step - accuracy: 0.3448 - loss: 1.8448 - val_accuracy: 0.5115 - val_loss: 1.3403\n",
            "Epoch 1/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 156ms/step - accuracy: 0.4689 - loss: 1.5535 - val_accuracy: 0.5584 - val_loss: 1.2405\n",
            "Epoch 2/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.5097 - loss: 1.2669 - val_accuracy: 0.5924 - val_loss: 1.1854\n",
            "Epoch 3/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 107ms/step - accuracy: 0.5604 - loss: 1.1121 - val_accuracy: 0.6264 - val_loss: 1.1132\n",
            "Epoch 4/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 107ms/step - accuracy: 0.6183 - loss: 0.9397 - val_accuracy: 0.6454 - val_loss: 1.0502\n",
            "Epoch 5/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 103ms/step - accuracy: 0.6553 - loss: 0.8388 - val_accuracy: 0.6424 - val_loss: 1.0402\n",
            "Epoch 6/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 110ms/step - accuracy: 0.6787 - loss: 0.7160 - val_accuracy: 0.6773 - val_loss: 0.9844\n",
            "Epoch 7/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 111ms/step - accuracy: 0.7185 - loss: 0.6447 - val_accuracy: 0.6883 - val_loss: 0.9577\n",
            "Epoch 8/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.7338 - loss: 0.5773 - val_accuracy: 0.7003 - val_loss: 0.9105\n",
            "Epoch 9/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 106ms/step - accuracy: 0.7655 - loss: 0.4958 - val_accuracy: 0.7183 - val_loss: 0.8809\n",
            "Epoch 10/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 104ms/step - accuracy: 0.7768 - loss: 0.4472 - val_accuracy: 0.7113 - val_loss: 0.8849\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       akiec       0.38      0.47      0.42        32\n",
            "         bcc       0.58      0.48      0.53        52\n",
            "         bkl       0.53      0.71      0.61       110\n",
            "          df       0.22      0.55      0.32        11\n",
            "         mel       0.35      0.69      0.46       112\n",
            "          nv       0.96      0.74      0.83       671\n",
            "        vasc       0.90      0.64      0.75        14\n",
            "\n",
            "    accuracy                           0.70      1002\n",
            "   macro avg       0.56      0.61      0.56      1002\n",
            "weighted avg       0.80      0.70      0.73      1002\n",
            "\n",
            "Saved: runs/resnet50/colab_run\n",
            "[master] Appended summary to: runs/experiments_master.csv\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os, json, time, csv, datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "# =============================\n",
        "# CONFIG (edit this in Colab)\n",
        "# =============================\n",
        "class Args:\n",
        "    data = \"/content/work/data\"   # <-- your dataset folder with train/val/test\n",
        "    epochs = 10\n",
        "    warmup = 2\n",
        "    size = 224\n",
        "    batch = 32\n",
        "    base_lr = 1e-4\n",
        "    ft_lr = 1e-5\n",
        "    unfreeze = 10\n",
        "    binary = 0\n",
        "    run_name = \"colab_run\"\n",
        "    out_dir = \"runs\"\n",
        "\n",
        "args = Args()\n",
        "\n",
        "# =============================\n",
        "# Functions\n",
        "# =============================\n",
        "def get_datasets(data_dir, img_size=(224, 224), batch=32, seed=42, binary=False):\n",
        "    def loader(split, shuffle):\n",
        "        return tf.keras.utils.image_dataset_from_directory(\n",
        "            os.path.join(data_dir, split),\n",
        "            image_size=img_size, batch_size=batch, seed=seed, shuffle=shuffle\n",
        "        )\n",
        "    ds_train = loader(\"train\", True)\n",
        "    ds_val   = loader(\"val\",   False)\n",
        "    ds_test  = loader(\"test\",  False)\n",
        "    class_names = ds_train.class_names\n",
        "\n",
        "    aug = keras.Sequential([\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.05),\n",
        "        layers.RandomZoom(0.1),\n",
        "    ])\n",
        "    ds_train = ds_train.map(lambda x, y: (aug(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds_train = ds_train.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    ds_val   = ds_val.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    ds_test  = ds_test.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    return ds_train, ds_val, ds_test, class_names, bool(binary)\n",
        "\n",
        "def compute_class_weights(ds, num_classes):\n",
        "    counts = np.zeros(num_classes, dtype=np.int64)\n",
        "    for _, y in ds.unbatch():\n",
        "        counts[int(y.numpy())] += 1\n",
        "    total = counts.sum()\n",
        "    return {i: float(total / (num_classes * max(counts[i], 1))) for i in range(num_classes)}\n",
        "\n",
        "def build_model(num_classes, img_size=(224, 224), binary=False):\n",
        "    inp = keras.Input(shape=(*img_size, 3))\n",
        "    x = tf.keras.applications.resnet50.preprocess_input(inp)\n",
        "    base = tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\", input_tensor=x)\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\", dtype=\"float32\")(x) if binary \\\n",
        "          else layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
        "    return keras.Model(inp, out), base\n",
        "\n",
        "def compile_and_fit(model, train_ds, val_ds, *, loss, lr, epochs, class_weight, ckpt_path):\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=loss, metrics=[\"accuracy\"])\n",
        "    os.makedirs(os.path.dirname(ckpt_path), exist_ok=True)\n",
        "    cbs = [\n",
        "        keras.callbacks.ModelCheckpoint(ckpt_path, save_best_only=True, monitor=\"val_accuracy\", mode=\"max\"),\n",
        "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor=\"val_accuracy\", mode=\"max\"),\n",
        "    ]\n",
        "    hist = model.fit(train_ds, validation_data=val_ds, epochs=epochs,\n",
        "                     class_weight=class_weight, callbacks=cbs)\n",
        "    return {k: [float(v) for v in vals] for k, vals in hist.history.items()}\n",
        "\n",
        "def eval_save(model, ds_test, names, out_dir, binary=False):\n",
        "    y_true, y_pred = [], []\n",
        "    for x, y in ds_test:\n",
        "        p = model.predict(x, verbose=0)\n",
        "        yp = (p.reshape(-1) >= 0.5).astype(int) if binary else p.argmax(axis=1)\n",
        "        y_true += y.numpy().tolist(); y_pred += yp.tolist()\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    acc = float(accuracy_score(y_true, y_pred))\n",
        "    f1  = float(f1_score(y_true, y_pred, average=(\"binary\" if binary else \"macro\")))\n",
        "    rep = classification_report(y_true, y_pred, target_names=names)\n",
        "    cm  = confusion_matrix(y_true, y_pred).tolist()\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    json.dump({\"accuracy\": acc, \"macro_f1\": f1, \"confusion_matrix\": cm},\n",
        "              open(os.path.join(out_dir,\"metrics.json\"),\"w\"), indent=2)\n",
        "    open(os.path.join(out_dir,\"classification_report.txt\"),\"w\").write(rep)\n",
        "    json.dump(names, open(os.path.join(out_dir,\"classes.json\"),\"w\"), indent=2)\n",
        "    print(rep); print(\"Saved:\", out_dir)\n",
        "    return acc, f1\n",
        "\n",
        "def merge_histories(h1, h2):\n",
        "    out = {}\n",
        "    keys = set(h1.keys()) | set(h2.keys())\n",
        "    for k in keys:\n",
        "        out[k] = (h1.get(k, []) + h2.get(k, []))\n",
        "    return out\n",
        "\n",
        "def write_epoch_csv(history, path_csv):\n",
        "    rows = []\n",
        "    n = max(len(history.get(\"accuracy\", [])), len(history.get(\"loss\", [])))\n",
        "    for i in range(n):\n",
        "        rows.append({\n",
        "            \"epoch\": i+1,\n",
        "            \"accuracy\": history.get(\"accuracy\", [None]*n)[i],\n",
        "            \"loss\": history.get(\"loss\", [None]*n)[i],\n",
        "            \"val_accuracy\": history.get(\"val_accuracy\", [None]*n)[i],\n",
        "            \"val_loss\": history.get(\"val_loss\", [None]*n)[i],\n",
        "        })\n",
        "    import pandas as pd\n",
        "    pd.DataFrame(rows).to_csv(path_csv, index=False)\n",
        "\n",
        "def append_master_row(master_csv, row_dict):\n",
        "    headers = [\"timestamp\",\"run_name\",\"data\",\"img_size\",\"batch\",\"warmup\",\"epochs\",\"unfreeze\",\n",
        "               \"base_lr\",\"ft_lr\",\"binary\",\"best_val_acc\",\"best_val_loss\",\"test_acc\",\"test_macro_f1\"]\n",
        "    os.makedirs(os.path.dirname(master_csv), exist_ok=True)\n",
        "    file_exists = os.path.isfile(master_csv)\n",
        "    with open(master_csv, \"a\", newline=\"\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=headers)\n",
        "        if not file_exists:\n",
        "            w.writeheader()\n",
        "        w.writerow({k: row_dict.get(k) for k in headers})\n",
        "\n",
        "# =============================\n",
        "# MAIN\n",
        "# =============================\n",
        "def main(a):\n",
        "    run = a.run_name or time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    out_root = a.out_dir if a.out_dir else \"runs\"\n",
        "    out = os.path.join(out_root, \"resnet50\", run)\n",
        "    os.makedirs(out, exist_ok=True)\n",
        "\n",
        "    ds_tr, ds_va, ds_te, names, binary = get_datasets(a.data, (a.size, a.size), a.batch, binary=bool(a.binary))\n",
        "    ncls = 2 if binary else len(names)\n",
        "    class_weight = compute_class_weights(ds_tr, ncls)\n",
        "\n",
        "    model, base = build_model(ncls, (a.size, a.size), binary)\n",
        "    loss = \"binary_crossentropy\" if binary else keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "    # warmup\n",
        "    base.trainable = False\n",
        "    hist_warm = compile_and_fit(model, ds_tr, ds_va, loss=loss, lr=a.base_lr,\n",
        "                                epochs=max(1, a.warmup), class_weight=class_weight,\n",
        "                                ckpt_path=os.path.join(out, \"best.keras\"))\n",
        "\n",
        "    # fine-tune\n",
        "    base.trainable = True\n",
        "    if a.unfreeze > 0 and a.unfreeze < len(base.layers):\n",
        "        for l in base.layers[:-a.unfreeze]:\n",
        "            l.trainable = False\n",
        "    hist_ft = compile_and_fit(model, ds_tr, ds_va, loss=loss, lr=a.ft_lr,\n",
        "                              epochs=a.epochs, class_weight=class_weight,\n",
        "                              ckpt_path=os.path.join(out, \"best.keras\"))\n",
        "\n",
        "    # histories\n",
        "    history = merge_histories(hist_warm, hist_ft)\n",
        "    json.dump(history, open(os.path.join(out,\"history.json\"),\"w\"), indent=2)\n",
        "    write_epoch_csv(history, os.path.join(out,\"history_epoch.csv\"))\n",
        "\n",
        "    # evaluate\n",
        "    test_acc, test_f1 = eval_save(model, ds_te, names, out, binary)\n",
        "\n",
        "    # master CSV\n",
        "    master_csv = os.path.join(out_root, \"experiments_master.csv\")\n",
        "    best_idx = int(np.nanargmax(history.get(\"val_accuracy\", [np.nan])))\n",
        "    best_val_acc  = float(history[\"val_accuracy\"][best_idx]) if \"val_accuracy\" in history else None\n",
        "    best_val_loss = float(history[\"val_loss\"][best_idx]) if \"val_loss\" in history else None\n",
        "\n",
        "    append_master_row(master_csv, {\n",
        "        \"timestamp\": datetime.datetime.now().isoformat(timespec=\"seconds\"),\n",
        "        \"run_name\": run,\n",
        "        \"data\": a.data,\n",
        "        \"img_size\": a.size,\n",
        "        \"batch\": a.batch,\n",
        "        \"warmup\": a.warmup,\n",
        "        \"epochs\": a.epochs,\n",
        "        \"unfreeze\": a.unfreeze,\n",
        "        \"base_lr\": a.base_lr,\n",
        "        \"ft_lr\": a.ft_lr,\n",
        "        \"binary\": int(a.binary),\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "        \"best_val_loss\": best_val_loss,\n",
        "        \"test_acc\": test_acc,\n",
        "        \"test_macro_f1\": test_f1,\n",
        "    })\n",
        "    print(f\"[master] Appended summary to: {master_csv}\")\n",
        "\n",
        "# =============================\n",
        "# RUN\n",
        "# =============================\n",
        "main(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "E9ADlRFE0v-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7bb172-b426-41e5-beda-7d4648b22f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists: True\n",
            "Splits: ['test', 'val', 'train']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Exists:\", os.path.isdir(\"/content/work/data\"))\n",
        "print(\"Splits:\", os.listdir(\"/content/work/data\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure the folder exists\n",
        "!mkdir -p /content/members"
      ],
      "metadata": {
        "id": "eTUMX_6x3ysG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/members/run_resnet50.py\n",
        "#!/usr/bin/env python3\n",
        "import os, json, time, argparse, csv, datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "def get_datasets(data_dir, img_size=(224,224), batch=32, seed=42, binary=False):\n",
        "    def loader(split, shuffle):\n",
        "        return tf.keras.utils.image_dataset_from_directory(\n",
        "            os.path.join(data_dir, split),\n",
        "            image_size=img_size, batch_size=batch, seed=seed, shuffle=shuffle\n",
        "        )\n",
        "    ds_train = loader(\"train\", True); ds_val = loader(\"val\", False); ds_test = loader(\"test\", False)\n",
        "    class_names = ds_train.class_names\n",
        "    aug = keras.Sequential([layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.05), layers.RandomZoom(0.1)])\n",
        "    ds_train = ds_train.map(lambda x,y:(aug(x),y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds_train = ds_train.cache().prefetch(tf.data.AUTOTUNE); ds_val = ds_val.cache().prefetch(tf.data.AUTOTUNE); ds_test = ds_test.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    return ds_train, ds_val, ds_test, class_names, bool(binary)\n",
        "\n",
        "def compute_class_weights(ds, n):\n",
        "    c = np.zeros(n, dtype=np.int64)\n",
        "    for _, y in ds.unbatch(): c[int(y.numpy())]+=1\n",
        "    tot=c.sum(); return {i: float(tot/(n*max(c[i],1))) for i in range(n)}\n",
        "\n",
        "def build_model(num_classes, img_size=(224,224), binary=False):\n",
        "    inp = keras.Input(shape=(*img_size,3))\n",
        "    x = tf.keras.applications.resnet50.preprocess_input(inp)\n",
        "    base = tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\", input_tensor=x)\n",
        "    x = layers.GlobalAveragePooling2D()(base.output); x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\", dtype=\"float32\")(x) if binary else layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
        "    return keras.Model(inp,out), base\n",
        "\n",
        "def compile_and_fit(model, train_ds, val_ds, *, loss, lr, epochs, class_weight, ckpt_path):\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=loss, metrics=[\"accuracy\"])\n",
        "    os.makedirs(os.path.dirname(ckpt_path), exist_ok=True)\n",
        "    cbs=[keras.callbacks.ModelCheckpoint(ckpt_path, save_best_only=True, monitor=\"val_accuracy\", mode=\"max\"),\n",
        "         keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor=\"val_accuracy\", mode=\"max\")]\n",
        "    hist=model.fit(train_ds, validation_data=val_ds, epochs=epochs, class_weight=class_weight, callbacks=cbs)\n",
        "    return {k:[float(v) for v in vals] for k,vals in hist.history.items()}\n",
        "\n",
        "def eval_save(model, ds_test, names, out_dir, binary=False):\n",
        "    y_true,y_pred=[],[]\n",
        "    for x,y in ds_test:\n",
        "        p=model.predict(x,verbose=0)\n",
        "        yp=(p.reshape(-1)>=0.5).astype(int) if binary else p.argmax(axis=1)\n",
        "        y_true+=y.numpy().tolist(); y_pred+=yp.tolist()\n",
        "    y_true=np.array(y_true); y_pred=np.array(y_pred)\n",
        "    acc=float(accuracy_score(y_true,y_pred)); f1=float(f1_score(y_true,y_pred,average=(\"binary\" if binary else \"macro\")))\n",
        "    rep=classification_report(y_true,y_pred,target_names=names); cm=confusion_matrix(y_true,y_pred).tolist()\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    json.dump({\"accuracy\":acc,\"macro_f1\":f1,\"confusion_matrix\":cm}, open(os.path.join(out_dir,\"metrics.json\"),\"w\"), indent=2)\n",
        "    open(os.path.join(out_dir,\"classification_report.txt\"),\"w\").write(rep)\n",
        "    json.dump(names, open(os.path.join(out_dir,\"classes.json\"),\"w\"), indent=2)\n",
        "    print(rep); print(\"Saved:\", out_dir)\n",
        "    return acc,f1\n",
        "\n",
        "def merge_hist(h1,h2):\n",
        "    keys=set(h1.keys())|set(h2.keys())\n",
        "    return {k:(h1.get(k,[])+h2.get(k,[])) for k in keys}\n",
        "\n",
        "def write_epoch_csv(history, path_csv):\n",
        "    import pandas as pd\n",
        "    n=max(len(history.get(\"accuracy\",[])), len(history.get(\"loss\",[])))\n",
        "    rows=[{\n",
        "        \"epoch\":i+1,\n",
        "        \"accuracy\":history.get(\"accuracy\",[None]*n)[i],\n",
        "        \"loss\":history.get(\"loss\",[None]*n)[i],\n",
        "        \"val_accuracy\":history.get(\"val_accuracy\",[None]*n)[i],\n",
        "        \"val_loss\":history.get(\"val_loss\",[None]*n)[i],\n",
        "    } for i in range(n)]\n",
        "    pd.DataFrame(rows).to_csv(path_csv, index=False)\n",
        "\n",
        "def append_master_row(master_csv, row):\n",
        "    headers=[\"timestamp\",\"run_name\",\"data\",\"img_size\",\"batch\",\"warmup\",\"epochs\",\"unfreeze\",\"base_lr\",\"ft_lr\",\"binary\",\"best_val_acc\",\"best_val_loss\",\"test_acc\",\"test_macro_f1\"]\n",
        "    os.makedirs(os.path.dirname(master_csv), exist_ok=True)\n",
        "    new=not os.path.isfile(master_csv)\n",
        "    with open(master_csv,\"a\",newline=\"\") as f:\n",
        "        w=csv.DictWriter(f, fieldnames=headers)\n",
        "        if new: w.writeheader()\n",
        "        w.writerow({k:row.get(k) for k in headers})\n",
        "\n",
        "def main(a):\n",
        "    run=a.run_name or time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    out_root=a.out_dir or \"runs\"\n",
        "    out=os.path.join(out_root,\"resnet50\",run); os.makedirs(out,exist_ok=True)\n",
        "\n",
        "    ds_tr,ds_va,ds_te,names,binary=get_datasets(a.data,(a.size,a.size),a.batch,binary=bool(a.binary))\n",
        "    ncls=2 if binary else len(names)\n",
        "    class_weight=compute_class_weights(ds_tr,ncls)\n",
        "\n",
        "    model,base=build_model(ncls,(a.size,a.size),binary)\n",
        "    loss=\"binary_crossentropy\" if binary else keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "    base.trainable=False\n",
        "    hist_warm=compile_and_fit(model,ds_tr,ds_va,loss=loss,lr=a.base_lr,epochs=max(1,a.warmup),class_weight=class_weight,ckpt_path=os.path.join(out,\"best.keras\"))\n",
        "\n",
        "    base.trainable=True\n",
        "    if a.unfreeze>0 and a.unfreeze<len(base.layers):\n",
        "        for l in base.layers[:-a.unfreeze]: l.trainable=False\n",
        "    hist_ft=compile_and_fit(model,ds_tr,ds_va,loss=loss,lr=a.ft_lr,epochs=a.epochs,class_weight=class_weight,ckpt_path=os.path.join(out,\"best.keras\"))\n",
        "\n",
        "    history=merge_hist(hist_warm,hist_ft)\n",
        "    json.dump(history, open(os.path.join(out,\"history.json\"),\"w\"), indent=2)\n",
        "    write_epoch_csv(history, os.path.join(out,\"history_epoch.csv\"))\n",
        "\n",
        "    test_acc,test_f1=eval_save(model,ds_te,names,out,binary)\n",
        "\n",
        "    master_csv=os.path.join(out_root,\"experiments_master.csv\")\n",
        "    best_idx=int(np.nanargmax(history.get(\"val_accuracy\",[np.nan])))\n",
        "    best_val_acc=float(history[\"val_accuracy\"][best_idx]) if \"val_accuracy\" in history else None\n",
        "    best_val_loss=float(history[\"val_loss\"][best_idx]) if \"val_loss\" in history else None\n",
        "    append_master_row(master_csv,{\n",
        "        \"timestamp\":datetime.datetime.now().isoformat(timespec=\"seconds\"),\n",
        "        \"run_name\":run,\"data\":a.data,\"img_size\":a.size,\"batch\":a.batch,\n",
        "        \"warmup\":a.warmup,\"epochs\":a.epochs,\"unfreeze\":a.unfreeze,\n",
        "        \"base_lr\":a.base_lr,\"ft_lr\":a.ft_lr,\"binary\":int(a.binary),\n",
        "        \"best_val_acc\":best_val_acc,\"best_val_loss\":best_val_loss,\n",
        "        \"test_acc\":test_acc,\"test_macro_f1\":test_f1\n",
        "    })\n",
        "    print(f\"[master] Appended summary to: {master_csv}\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    ap=argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--data\", required=True)\n",
        "    ap.add_argument(\"--epochs\", type=int, default=20)\n",
        "    ap.add_argument(\"--warmup\", type=int, default=3)\n",
        "    ap.add_argument(\"--size\", type=int, default=224)\n",
        "    ap.add_argument(\"--batch\", type=int, default=32)\n",
        "    ap.add_argument(\"--base_lr\", type=float, default=1e-4)\n",
        "    ap.add_argument(\"--ft_lr\", type=float, default=1e-5)\n",
        "    ap.add_argument(\"--unfreeze\", type=int, default=10)\n",
        "    ap.add_argument(\"--binary\", type=int, default=0)\n",
        "    ap.add_argument(\"--run_name\", default=\"\")\n",
        "    ap.add_argument(\"--out_dir\", default=\"runs\")\n",
        "    a=ap.parse_args(); main(a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE6KrY5e21xQ",
        "outputId": "bfaf7bdd-67f5-4fcb-9d0c-e910e351fe21"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/members/run_resnet50.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HIlzypPnwLjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a980774a-9355-4da0-e9da-69c46266b3cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 16:22:43.377190: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759508563.603122   22699 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759508563.663254   22699 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759508564.111369   22699 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759508564.111411   22699 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759508564.111416   22699 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759508564.111421   22699 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-03 16:22:44.154366: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Found 8012 files belonging to 7 classes.\n",
            "2025-10-03 16:22:54.455554: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1759508574.457063   22699 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Found 1001 files belonging to 7 classes.\n",
            "Found 1002 files belonging to 7 classes.\n",
            "2025-10-03 16:24:53.495832: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "Epoch 1/3\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1759508703.752023   22773 service.cc:152] XLA service 0x7f44dc002240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1759508703.752065   22773 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-10-03 16:25:04.016017: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1759508705.572411   22773 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2025-10-03 16:25:07.322394: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[32,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,56,56]{3,2,1,0} %bitcast.7409, f32[64,64,3,3]{3,2,1,0} %bitcast.7416, f32[64]{0} %bitcast.7418), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:25:07.779136: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[32,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,28,28]{3,2,1,0} %bitcast.7814, f32[128,128,3,3]{3,2,1,0} %bitcast.7821, f32[128]{0} %bitcast.7823), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:25:08.306498: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[32,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,14,14]{3,2,1,0} %bitcast.8342, f32[256,256,3,3]{3,2,1,0} %bitcast.8349, f32[256]{0} %bitcast.8351), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:25:08.807418: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[32,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,7,7]{3,2,1,0} %bitcast.9116, f32[512,512,3,3]{3,2,1,0} %bitcast.9123, f32[512]{0} %bitcast.9125), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "I0000 00:00:1759508711.069614   22773 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m250/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.2318 - loss: 2.35232025-10-03 16:25:33.852579: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[12,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,64,56,56]{3,2,1,0} %bitcast.7409, f32[64,64,3,3]{3,2,1,0} %bitcast.7416, f32[64]{0} %bitcast.7418), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:25:34.106051: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[12,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,128,28,28]{3,2,1,0} %bitcast.7814, f32[128,128,3,3]{3,2,1,0} %bitcast.7821, f32[128]{0} %bitcast.7823), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:25:34.346718: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[12,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,256,14,14]{3,2,1,0} %bitcast.8342, f32[256,256,3,3]{3,2,1,0} %bitcast.8349, f32[256]{0} %bitcast.8351), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:25:34.579062: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[12,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,512,7,7]{3,2,1,0} %bitcast.9116, f32[512,512,3,3]{3,2,1,0} %bitcast.9123, f32[512]{0} %bitcast.9125), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.2321 - loss: 2.35142025-10-03 16:25:47.848607: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[9,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,64,56,56]{3,2,1,0} %bitcast.4851, f32[64,64,3,3]{3,2,1,0} %bitcast.4858, f32[64]{0} %bitcast.4860), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:25:48.061088: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[9,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,128,28,28]{3,2,1,0} %bitcast.5256, f32[128,128,3,3]{3,2,1,0} %bitcast.5263, f32[128]{0} %bitcast.5265), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:25:48.267582: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[9,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,256,14,14]{3,2,1,0} %bitcast.5784, f32[256,256,3,3]{3,2,1,0} %bitcast.5791, f32[256]{0} %bitcast.5793), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:25:48.485488: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[9,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,512,7,7]{3,2,1,0} %bitcast.6558, f32[512,512,3,3]{3,2,1,0} %bitcast.6565, f32[512]{0} %bitcast.6567), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 161ms/step - accuracy: 0.2323 - loss: 2.3505 - val_accuracy: 0.4555 - val_loss: 1.4786\n",
            "Epoch 2/3\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 100ms/step - accuracy: 0.3815 - loss: 1.8525 - val_accuracy: 0.5195 - val_loss: 1.3241\n",
            "Epoch 3/3\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 98ms/step - accuracy: 0.4543 - loss: 1.6200 - val_accuracy: 0.5445 - val_loss: 1.2563\n",
            "Epoch 1/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 155ms/step - accuracy: 0.4480 - loss: 1.4279 - val_accuracy: 0.5584 - val_loss: 1.2084\n",
            "Epoch 2/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.5397 - loss: 1.1644 - val_accuracy: 0.5924 - val_loss: 1.1286\n",
            "Epoch 3/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 106ms/step - accuracy: 0.5754 - loss: 1.0556 - val_accuracy: 0.5984 - val_loss: 1.0919\n",
            "Epoch 4/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 106ms/step - accuracy: 0.6277 - loss: 0.8883 - val_accuracy: 0.6314 - val_loss: 1.0323\n",
            "Epoch 5/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 107ms/step - accuracy: 0.6636 - loss: 0.7939 - val_accuracy: 0.6404 - val_loss: 0.9755\n",
            "Epoch 6/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 107ms/step - accuracy: 0.6833 - loss: 0.7173 - val_accuracy: 0.6464 - val_loss: 0.9595\n",
            "Epoch 7/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 107ms/step - accuracy: 0.7155 - loss: 0.6249 - val_accuracy: 0.6773 - val_loss: 0.9025\n",
            "Epoch 8/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 108ms/step - accuracy: 0.7391 - loss: 0.5659 - val_accuracy: 0.6803 - val_loss: 0.8899\n",
            "Epoch 9/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 106ms/step - accuracy: 0.7692 - loss: 0.4974 - val_accuracy: 0.6883 - val_loss: 0.8541\n",
            "Epoch 10/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 106ms/step - accuracy: 0.7748 - loss: 0.4508 - val_accuracy: 0.7063 - val_loss: 0.8200\n",
            "Epoch 11/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 106ms/step - accuracy: 0.7981 - loss: 0.3917 - val_accuracy: 0.7213 - val_loss: 0.8050\n",
            "Epoch 12/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 106ms/step - accuracy: 0.8176 - loss: 0.3443 - val_accuracy: 0.7343 - val_loss: 0.7872\n",
            "Epoch 13/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 106ms/step - accuracy: 0.8314 - loss: 0.3081 - val_accuracy: 0.7373 - val_loss: 0.7691\n",
            "Epoch 14/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 106ms/step - accuracy: 0.8445 - loss: 0.2722 - val_accuracy: 0.7433 - val_loss: 0.7644\n",
            "Epoch 15/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 106ms/step - accuracy: 0.8529 - loss: 0.2479 - val_accuracy: 0.7572 - val_loss: 0.7352\n",
            "Epoch 16/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 106ms/step - accuracy: 0.8679 - loss: 0.2131 - val_accuracy: 0.7632 - val_loss: 0.7282\n",
            "Epoch 17/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 107ms/step - accuracy: 0.8778 - loss: 0.1808 - val_accuracy: 0.7642 - val_loss: 0.7099\n",
            "Epoch 18/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 102ms/step - accuracy: 0.8925 - loss: 0.1669 - val_accuracy: 0.7642 - val_loss: 0.7081\n",
            "Epoch 19/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 107ms/step - accuracy: 0.9105 - loss: 0.1426 - val_accuracy: 0.7722 - val_loss: 0.6978\n",
            "Epoch 20/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 107ms/step - accuracy: 0.9116 - loss: 0.1275 - val_accuracy: 0.7762 - val_loss: 0.7001\n",
            "2025-10-03 16:36:50.542546: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[10,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,64,56,56]{3,2,1,0} %bitcast.4540, f32[64,64,3,3]{3,2,1,0} %bitcast.4547, f32[64]{0} %bitcast.4549), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:36:50.767078: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[10,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,128,28,28]{3,2,1,0} %bitcast.4945, f32[128,128,3,3]{3,2,1,0} %bitcast.4952, f32[128]{0} %bitcast.4954), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:36:50.980439: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[10,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,256,14,14]{3,2,1,0} %bitcast.5473, f32[256,256,3,3]{3,2,1,0} %bitcast.5480, f32[256]{0} %bitcast.5482), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:36:51.219181: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[10,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,512,7,7]{3,2,1,0} %bitcast.6247, f32[512,512,3,3]{3,2,1,0} %bitcast.6254, f32[512]{0} %bitcast.6256), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:36:52.650924: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       akiec       0.52      0.34      0.42        32\n",
            "         bcc       0.68      0.48      0.56        52\n",
            "         bkl       0.61      0.76      0.68       110\n",
            "          df       0.31      0.36      0.33        11\n",
            "         mel       0.43      0.74      0.55       112\n",
            "          nv       0.95      0.84      0.89       671\n",
            "        vasc       1.00      0.64      0.78        14\n",
            "\n",
            "    accuracy                           0.78      1002\n",
            "   macro avg       0.64      0.60      0.60      1002\n",
            "weighted avg       0.82      0.78      0.79      1002\n",
            "\n",
            "Saved: /content/runs/resnet50/e20_b32\n",
            "[master] Appended summary to: /content/runs/experiments_master.csv\n",
            "2025-10-03 16:36:58.100889: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759509418.178925   27010 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759509418.196540   27010 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759509418.266072   27010 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759509418.266114   27010 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759509418.266125   27010 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759509418.266133   27010 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-03 16:36:58.282182: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Found 8012 files belonging to 7 classes.\n",
            "2025-10-03 16:37:05.396818: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1759509425.396978   27010 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Found 1001 files belonging to 7 classes.\n",
            "Found 1002 files belonging to 7 classes.\n",
            "2025-10-03 16:38:55.059688: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "Epoch 1/3\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1759509543.638102   27068 service.cc:152] XLA service 0x7ea7fc003dc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1759509543.638140   27068 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-10-03 16:39:03.834260: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1759509545.278953   27068 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2025-10-03 16:39:06.299054: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[16,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,56,56]{3,2,1,0} %bitcast.7409, f32[64,64,3,3]{3,2,1,0} %bitcast.7416, f32[64]{0} %bitcast.7418), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:39:06.578848: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[16,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,28,28]{3,2,1,0} %bitcast.7814, f32[128,128,3,3]{3,2,1,0} %bitcast.7821, f32[128]{0} %bitcast.7823), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:39:06.865531: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[16,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,256,14,14]{3,2,1,0} %bitcast.8342, f32[256,256,3,3]{3,2,1,0} %bitcast.8349, f32[256]{0} %bitcast.8351), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:39:07.140224: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[16,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,7,7]{3,2,1,0} %bitcast.9116, f32[512,512,3,3]{3,2,1,0} %bitcast.9123, f32[512]{0} %bitcast.9125), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "I0000 00:00:1759509549.184292   27068 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m499/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2816 - loss: 2.42552025-10-03 16:39:34.562655: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[12,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,64,56,56]{3,2,1,0} %bitcast.7409, f32[64,64,3,3]{3,2,1,0} %bitcast.7416, f32[64]{0} %bitcast.7418), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:39:34.816125: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[12,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,128,28,28]{3,2,1,0} %bitcast.7814, f32[128,128,3,3]{3,2,1,0} %bitcast.7821, f32[128]{0} %bitcast.7823), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:39:35.055815: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[12,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,256,14,14]{3,2,1,0} %bitcast.8342, f32[256,256,3,3]{3,2,1,0} %bitcast.8349, f32[256]{0} %bitcast.8351), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:39:35.315453: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[12,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,512,7,7]{3,2,1,0} %bitcast.9116, f32[512,512,3,3]{3,2,1,0} %bitcast.9123, f32[512]{0} %bitcast.9125), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2818 - loss: 2.42442025-10-03 16:39:48.796368: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[9,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,64,56,56]{3,2,1,0} %bitcast.4851, f32[64,64,3,3]{3,2,1,0} %bitcast.4858, f32[64]{0} %bitcast.4860), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:39:49.007975: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[9,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,128,28,28]{3,2,1,0} %bitcast.5256, f32[128,128,3,3]{3,2,1,0} %bitcast.5263, f32[128]{0} %bitcast.5265), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:39:49.208615: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[9,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,256,14,14]{3,2,1,0} %bitcast.5784, f32[256,256,3,3]{3,2,1,0} %bitcast.5791, f32[256]{0} %bitcast.5793), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:39:49.422329: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[9,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,512,7,7]{3,2,1,0} %bitcast.6558, f32[512,512,3,3]{3,2,1,0} %bitcast.6565, f32[512]{0} %bitcast.6567), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 86ms/step - accuracy: 0.2820 - loss: 2.4238 - val_accuracy: 0.5385 - val_loss: 1.3753\n",
            "Epoch 2/3\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 54ms/step - accuracy: 0.4444 - loss: 1.7306 - val_accuracy: 0.5934 - val_loss: 1.1760\n",
            "Epoch 3/3\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - accuracy: 0.5072 - loss: 1.5199 - val_accuracy: 0.6064 - val_loss: 1.1168\n",
            "Epoch 1/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 84ms/step - accuracy: 0.5330 - loss: 1.3492 - val_accuracy: 0.5954 - val_loss: 1.1839\n",
            "Epoch 2/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 61ms/step - accuracy: 0.5883 - loss: 1.0846 - val_accuracy: 0.6254 - val_loss: 1.1079\n",
            "Epoch 3/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 61ms/step - accuracy: 0.6377 - loss: 0.9238 - val_accuracy: 0.6484 - val_loss: 1.0320\n",
            "Epoch 4/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 58ms/step - accuracy: 0.6707 - loss: 0.7684 - val_accuracy: 0.6464 - val_loss: 1.0086\n",
            "Epoch 5/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 61ms/step - accuracy: 0.7030 - loss: 0.6496 - val_accuracy: 0.6783 - val_loss: 0.9324\n",
            "Epoch 6/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 61ms/step - accuracy: 0.7404 - loss: 0.5693 - val_accuracy: 0.6893 - val_loss: 0.9050\n",
            "Epoch 7/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - accuracy: 0.7690 - loss: 0.4756 - val_accuracy: 0.7083 - val_loss: 0.8638\n",
            "Epoch 8/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - accuracy: 0.7877 - loss: 0.4041 - val_accuracy: 0.7113 - val_loss: 0.8693\n",
            "Epoch 9/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 61ms/step - accuracy: 0.8072 - loss: 0.3461 - val_accuracy: 0.7233 - val_loss: 0.8282\n",
            "Epoch 10/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - accuracy: 0.8324 - loss: 0.2862 - val_accuracy: 0.7313 - val_loss: 0.8101\n",
            "Epoch 11/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - accuracy: 0.8449 - loss: 0.2442 - val_accuracy: 0.7393 - val_loss: 0.7960\n",
            "Epoch 12/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - accuracy: 0.8727 - loss: 0.2023 - val_accuracy: 0.7562 - val_loss: 0.7604\n",
            "Epoch 13/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - accuracy: 0.8899 - loss: 0.1706 - val_accuracy: 0.7612 - val_loss: 0.7644\n",
            "Epoch 14/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 61ms/step - accuracy: 0.9070 - loss: 0.1365 - val_accuracy: 0.7762 - val_loss: 0.7450\n",
            "Epoch 15/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 58ms/step - accuracy: 0.9183 - loss: 0.1126 - val_accuracy: 0.7762 - val_loss: 0.7485\n",
            "Epoch 16/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 61ms/step - accuracy: 0.9366 - loss: 0.0900 - val_accuracy: 0.7852 - val_loss: 0.7380\n",
            "Epoch 17/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 61ms/step - accuracy: 0.9481 - loss: 0.0752 - val_accuracy: 0.7872 - val_loss: 0.7543\n",
            "Epoch 18/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - accuracy: 0.9600 - loss: 0.0578 - val_accuracy: 0.7962 - val_loss: 0.7403\n",
            "Epoch 19/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 59ms/step - accuracy: 0.9708 - loss: 0.0460 - val_accuracy: 0.7912 - val_loss: 0.7818\n",
            "Epoch 20/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - accuracy: 0.9795 - loss: 0.0368 - val_accuracy: 0.8072 - val_loss: 0.7617\n",
            "Epoch 21/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 58ms/step - accuracy: 0.9856 - loss: 0.0287 - val_accuracy: 0.7952 - val_loss: 0.8202\n",
            "Epoch 22/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 58ms/step - accuracy: 0.9912 - loss: 0.0228 - val_accuracy: 0.7982 - val_loss: 0.8285\n",
            "Epoch 23/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 61ms/step - accuracy: 0.9941 - loss: 0.0168 - val_accuracy: 0.8102 - val_loss: 0.8299\n",
            "Epoch 24/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 58ms/step - accuracy: 0.9982 - loss: 0.0124 - val_accuracy: 0.8092 - val_loss: 0.8889\n",
            "Epoch 25/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 58ms/step - accuracy: 0.9985 - loss: 0.0093 - val_accuracy: 0.8052 - val_loss: 0.9000\n",
            "Epoch 26/40\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 58ms/step - accuracy: 0.9994 - loss: 0.0075 - val_accuracy: 0.8082 - val_loss: 0.9343\n",
            "2025-10-03 16:55:04.850197: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[10,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,64,56,56]{3,2,1,0} %bitcast.4540, f32[64,64,3,3]{3,2,1,0} %bitcast.4547, f32[64]{0} %bitcast.4549), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:55:05.073156: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[10,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,128,28,28]{3,2,1,0} %bitcast.4945, f32[128,128,3,3]{3,2,1,0} %bitcast.4952, f32[128]{0} %bitcast.4954), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:55:05.290645: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[10,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,256,14,14]{3,2,1,0} %bitcast.5473, f32[256,256,3,3]{3,2,1,0} %bitcast.5480, f32[256]{0} %bitcast.5482), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:55:05.562631: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[10,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,512,7,7]{3,2,1,0} %bitcast.6247, f32[512,512,3,3]{3,2,1,0} %bitcast.6254, f32[512]{0} %bitcast.6256), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-03 16:55:07.230990: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       akiec       0.57      0.41      0.47        32\n",
            "         bcc       0.71      0.52      0.60        52\n",
            "         bkl       0.61      0.75      0.67       110\n",
            "          df       0.42      0.45      0.43        11\n",
            "         mel       0.49      0.71      0.58       112\n",
            "          nv       0.95      0.88      0.91       671\n",
            "        vasc       0.90      0.64      0.75        14\n",
            "\n",
            "    accuracy                           0.80      1002\n",
            "   macro avg       0.66      0.62      0.63      1002\n",
            "weighted avg       0.83      0.80      0.81      1002\n",
            "\n",
            "Saved: /content/runs/resnet50/e40_b16\n",
            "[master] Appended summary to: /content/runs/experiments_master.csv\n"
          ]
        }
      ],
      "source": [
        "# run 1\n",
        "!python /content/members/run_resnet50.py \\\n",
        "  --data \"/content/work/data\" \\\n",
        "  --epochs 20 --warmup 3 --unfreeze 10 \\\n",
        "  --batch 32 --base_lr 1e-4 --ft_lr 1e-5 \\\n",
        "  --out_dir /content/runs --run_name e20_b32\n",
        "\n",
        "# run 2\n",
        "!python /content/members/run_resnet50.py \\\n",
        "  --data \"/content/work/data\" \\\n",
        "  --epochs 40 --warmup 3 --unfreeze 10 \\\n",
        "  --batch 16 --base_lr 1e-4 --ft_lr 1e-5 \\\n",
        "  --out_dir /content/runs --run_name e40_b16\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run 1 (baseline: 20 epochs, batch 32)\n",
        "# !python /content/members/run_resnet50.py \\\n",
        "#   --data \"/content/work/data\" \\\n",
        "#   --epochs 20 --warmup 3 --unfreeze 10 \\\n",
        "#   --batch 32 --base_lr 1e-4 --ft_lr 1e-5 \\\n",
        "#   --out_dir /content/runs --run_name e20_b32\n",
        "\n",
        "# # run 2 (longer training, smaller batch)\n",
        "# !python /content/members/run_resnet50.py \\\n",
        "#   --data \"/content/work/data\" \\\n",
        "#   --epochs 40 --warmup 3 --unfreeze 10 \\\n",
        "#   --batch 16 --base_lr 1e-4 --ft_lr 1e-5 \\\n",
        "#   --out_dir /content/runs --run_name e40_b16\n",
        "\n",
        "# run 3 (fewer epochs, larger batch — tests faster convergence)\n",
        "!python /content/members/run_resnet50.py \\\n",
        "  --data \"/content/work/data\" \\\n",
        "  --epochs 15 --warmup 2 --unfreeze 10 \\\n",
        "  --batch 64 --base_lr 1e-4 --ft_lr 1e-5 \\\n",
        "  --out_dir /content/runs --run_name e15_b64\n",
        "\n",
        "# run 4 (more fine-tuning, unfreeze 30 layers)\n",
        "!python /content/members/run_resnet50.py \\\n",
        "  --data \"/content/work/data\" \\\n",
        "  --epochs 30 --warmup 3 --unfreeze 30 \\\n",
        "  --batch 32 --base_lr 5e-5 --ft_lr 1e-5 \\\n",
        "  --out_dir /content/runs --run_name e30_b32_unf30\n",
        "\n",
        "# run 5 (higher learning rate for fine-tune)\n",
        "!python /content/members/run_resnet50.py \\\n",
        "  --data \"/content/work/data\" \\\n",
        "  --epochs 25 --warmup 3 --unfreeze 10 \\\n",
        "  --batch 32 --base_lr 1e-4 --ft_lr 5e-5 \\\n",
        "  --out_dir /content/runs --run_name e25_b32_ftlr5e5\n",
        "\n",
        "# run 6 (very small batch, stress test on gradients)\n",
        "!python /content/members/run_resnet50.py \\\n",
        "  --data \"/content/work/data\" \\\n",
        "  --epochs 25 --warmup 3 --unfreeze 10 \\\n",
        "  --batch 8 --base_lr 1e-4 --ft_lr 1e-5 \\\n",
        "  --out_dir /content/runs --run_name e25_b8\n"
      ],
      "metadata": {
        "id": "3YliC6IT5Ady"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify per-run files\n",
        "!ls -lah /content/runs/resnet50/e20_b32\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-R3f_2v4iLe",
        "outputId": "5ebec260-7f67-4205-8bf3-e951523e81bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 125M\n",
            "drwxr-xr-x 2 root root 4.0K Oct  3 16:36 .\n",
            "drwxr-xr-x 5 root root 4.0K Oct  3 16:37 ..\n",
            "-rw-r--r-- 1 root root 125M Oct  3 16:36 best.keras\n",
            "-rw-r--r-- 1 root root   66 Oct  3 16:36 classes.json\n",
            "-rw-r--r-- 1 root root  596 Oct  3 16:36 classification_report.txt\n",
            "-rw-r--r-- 1 root root 1.8K Oct  3 16:36 history_epoch.csv\n",
            "-rw-r--r-- 1 root root 2.3K Oct  3 16:36 history.json\n",
            "-rw-r--r-- 1 root root  633 Oct  3 16:36 metrics.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Master CSV (all runs + scores)\n",
        "!sed -n '1,10p' /content/runs/experiments_master.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USOH5j-q4l3p",
        "outputId": "15ec5f85-3d03-4f7e-e87f-6745f6a66288"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timestamp,run_name,data,img_size,batch,warmup,epochs,unfreeze,base_lr,ft_lr,binary,best_val_acc,best_val_loss,test_acc,test_macro_f1\r\n",
            "2025-10-03T15:52:25,colab_run,/content/work/data,224,32,2,10,10,0.0001,1e-05,0,0.7182817459106445,0.8808948993682861,0.7035928143712575,0.5599759908482217\r\n",
            "2025-10-03T16:36:52,e20_b32,/content/work/data,224,32,3,20,10,0.0001,1e-05,0,0.7762237787246704,0.7001172304153442,0.779441117764471,0.6018622911554392\r\n",
            "2025-10-03T16:55:07,e40_b16,/content/work/data,224,16,3,40,10,0.0001,1e-05,0,0.8101897835731506,0.8298619985580444,0.8033932135728543,0.6312824143804363\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSjXLioyariV",
        "outputId": "20f08144-ad0f-47da-9702-11584696f771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        392.75M 100%  114.16MB/s    0:00:03 (xfr#19, to-chk=0/24)\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/colab_run/best.keras\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/colab_run/classes.json\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/colab_run/classification_report.txt\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/colab_run/history.json\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/colab_run/history_epoch.csv\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/colab_run/metrics.json\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/e20_b32/best.keras\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/e20_b32/classes.json\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/e20_b32/classification_report.txt\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/e20_b32/history.json\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/e20_b32/history_epoch.csv\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/e20_b32/metrics.json\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/e40_b16/best.keras\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/e40_b16/classes.json\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/e40_b16/classification_report.txt\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/e40_b16/history.json\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/e40_b16/history_epoch.csv\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/e40_b16/metrics.json\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/experiments_master.csv\n"
          ]
        }
      ],
      "source": [
        "#Save results back to Drive (persistent)\n",
        "\n",
        "# Save all runs\n",
        "!mkdir -p \"/content/drive/MyDrive/SKIN_CANCER_RESULTS\"\n",
        "!rsync -ah --info=progress2 \"/content/runs/\" \"/content/drive/MyDrive/SKIN_CANCER_RESULTS/\"\n",
        "\n",
        "# Inspect what's saved\n",
        "!find \"/content/drive/MyDrive/SKIN_CANCER_RESULTS\" -maxdepth 3 -type f | head -n 20"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}