{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Kasundi**- ResNet50 (transfer + small unfreeze)"
      ],
      "metadata": {
        "id": "gMJQgEPo2NRi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbFv-2DSZ_Hx",
        "outputId": "daa05dbd-44af-4cdb-de44-21307264b5db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Check GPU\n",
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Npv_otULaBW2"
      },
      "outputs": [],
      "source": [
        "# Basic deps for the split script + training\n",
        "!pip -q install pandas scikit-learn tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-vYKwCeaEBZ",
        "outputId": "93fec55a-078b-4290-ece9-6a1737fc6c71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#1) Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na1Idn9AaMmI",
        "outputId": "64031ca5-8daa-46a0-87d3-c743d0d422c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Local RAW_DIR: total 2.6G\n",
            "-rw------- 1 root root 1.3G Oct  8 06:58 HAM10000_images_part_1.zip\n",
            "-rw------- 1 root root 1.4G Oct  8 06:59 HAM10000_images_part_2.zip\n",
            "-rw------- 1 root root 551K Oct  8 07:00 HAM10000_metadata.csv\n"
          ]
        }
      ],
      "source": [
        "#2) Define paths to your files in root of My Drive and copy to fast local SSD\n",
        "# Paths on Drive (root)\n",
        "ZIP1 = \"/content/drive/MyDrive/HAM10000_images_part_1.zip\"\n",
        "ZIP2 = \"/content/drive/MyDrive/HAM10000_images_part_2.zip\"\n",
        "META = \"/content/drive/MyDrive/HAM10000_metadata.csv\"\n",
        "\n",
        "# Local working area on Colab SSD\n",
        "WORK     = \"/content/work\"\n",
        "RAW_DIR  = f\"{WORK}/raw\"\n",
        "EXTRACT  = f\"{WORK}/ham10000_extracted\"\n",
        "DATA_DIR = f\"{WORK}/data\"\n",
        "\n",
        "import os, subprocess, pathlib\n",
        "os.makedirs(RAW_DIR, exist_ok=True)\n",
        "os.makedirs(EXTRACT, exist_ok=True)\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "# Copy only if missing (fast on later sessions)\n",
        "print(subprocess.getoutput(f'rsync -ah --ignore-existing \"{ZIP1}\" \"{ZIP2}\" \"{META}\" \"{RAW_DIR}/\"'))\n",
        "print(\"Local RAW_DIR:\", subprocess.getoutput(f'ls -lh \"{RAW_DIR}\"'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wLW-i61aKxl",
        "outputId": "8954a5f9-a480-4c52-a8ea-ec3e101e9de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 340K\n",
            "drwxr-xr-x 2 root root 164K Sep 29 20:38 HAM10000_images_part_1\n",
            "drwxrwxrwx 2 root root 168K Sep 29 15:08 HAM10000_images_part_2\n"
          ]
        }
      ],
      "source": [
        "#3) Unzip locally (NOT to Drive)\n",
        "!mkdir -p /content/work/ham10000_extracted\n",
        "!unzip -q /content/work/raw/HAM10000_images_part_1.zip -d /content/work/ham10000_extracted/\n",
        "!unzip -q /content/work/raw/HAM10000_images_part_2.zip -d /content/work/ham10000_extracted/\n",
        "!ls -lh /content/work/ham10000_extracted | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G4_9Jqme8eS"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyi02Yv5g6cx",
        "outputId": "997cff0d-3751-414a-ccc4-7e5991f98385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/scripts/split_ham10000.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/scripts/split_ham10000.py\n",
        "#!/usr/bin/env python3\n",
        "import argparse, os, shutil, zipfile\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "def unzip_if_needed(zip_path: Path, extract_dir: Path):\n",
        "    extract_dir.mkdir(parents=True, exist_ok=True)\n",
        "    # If any jpgs already exist anywhere under extract_dir, skip\n",
        "    if any(extract_dir.rglob(\"*.jpg\")):\n",
        "        print(f\"[skip] Images already present under: {extract_dir}\")\n",
        "        return\n",
        "    assert zip_path.exists(), f\"Missing: {zip_path}\"\n",
        "    print(f\"[unzip] {zip_path.name} -> {extract_dir}\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "        z.extractall(extract_dir)\n",
        "\n",
        "def index_images(img_root: Path):\n",
        "    \"\"\"\n",
        "    Build a dict: image_id (without .jpg) -> full path\n",
        "    Recurses under img_root to handle both 'HAM10000_images' and '..._part_1/part_2' layouts.\n",
        "    \"\"\"\n",
        "    mapping = {}\n",
        "    for p in img_root.rglob(\"*.jpg\"):\n",
        "        mapping[p.stem] = str(p)\n",
        "    return mapping\n",
        "\n",
        "def build_splits(meta_csv: Path, img_root: Path, train_pct: float, val_pct: float, test_pct: float, seed: int):\n",
        "    assert abs((train_pct + val_pct + test_pct) - 1.0) < 1e-6, \"Splits must sum to 1.0\"\n",
        "    meta = pd.read_csv(meta_csv)\n",
        "    img_map = index_images(img_root)\n",
        "    meta[\"image_path\"] = meta[\"image_id\"].map(img_map)\n",
        "    meta = meta.dropna(subset=[\"image_path\"]).copy()\n",
        "\n",
        "    # quick sanity\n",
        "    print(f\"[info] Found {len(img_map)} jpgs under {img_root}\")\n",
        "    print(f\"[info] Matched rows with metadata: {len(meta)}\")\n",
        "\n",
        "    train_df, temp_df = train_test_split(\n",
        "        meta, test_size=1.0-train_pct, stratify=meta[\"dx\"], random_state=seed\n",
        "    )\n",
        "    test_rel = test_pct / (val_pct + test_pct)\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df, test_size=test_rel, stratify=temp_df[\"dx\"], random_state=seed\n",
        "    )\n",
        "    return train_df, val_df, test_df, sorted(meta[\"dx\"].unique())\n",
        "\n",
        "def materialize_split(df: pd.DataFrame, split_name: str, out_root: Path):\n",
        "    base = out_root / split_name\n",
        "    base.mkdir(parents=True, exist_ok=True)\n",
        "    for cls in sorted(df[\"dx\"].unique()):\n",
        "        (base / cls).mkdir(parents=True, exist_ok=True)\n",
        "    for _, r in tqdm(df.iterrows(), total=len(df), desc=f\"{split_name:>5}\", unit=\"img\"):\n",
        "        src = Path(r[\"image_path\"])\n",
        "        dst = base / r[\"dx\"] / src.name\n",
        "        if not dst.exists():\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "def print_counts(data_dir: Path):\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        base = data_dir / split\n",
        "        if base.exists():\n",
        "            counts = {\n",
        "                d.name: len(list((base / d).glob(\"*\")))\n",
        "                for d in base.iterdir() if d.is_dir()\n",
        "            }\n",
        "            print(split, counts)\n",
        "\n",
        "def main():\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--project_dir\", default=\".\")\n",
        "    p.add_argument(\"--train\", type=float, default=0.8)\n",
        "    p.add_argument(\"--val\",   type=float, default=0.1)\n",
        "    p.add_argument(\"--test\",  type=float, default=0.1)\n",
        "    p.add_argument(\"--seed\",  type=int, default=42)\n",
        "    p.add_argument(\"--clean\", action=\"store_true\")\n",
        "    args = p.parse_args()\n",
        "\n",
        "    project = Path(args.project_dir).resolve()\n",
        "    raw_dir  = project / \"raw\"\n",
        "    data_dir = project / \"data\"\n",
        "    extract  = project / \"ham10000_extracted\"   # we recurse under this folder\n",
        "    imgs_root = extract                         # <-- recursive root\n",
        "\n",
        "    part1 = raw_dir / \"HAM10000_images_part_1.zip\"\n",
        "    part2 = raw_dir / \"HAM10000_images_part_2.zip\"\n",
        "    meta  = raw_dir / \"HAM10000_metadata.csv\"\n",
        "\n",
        "    extract.mkdir(parents=True, exist_ok=True)\n",
        "    data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    unzip_if_needed(part1, extract)\n",
        "    unzip_if_needed(part2, extract)\n",
        "\n",
        "    train_df, val_df, test_df, classes = build_splits(\n",
        "        meta, imgs_root, args.train, args.val, args.test, args.seed\n",
        "    )\n",
        "\n",
        "    if args.clean:\n",
        "        for s in [\"train\", \"val\", \"test\"]:\n",
        "            target = data_dir / s\n",
        "            if target.exists():\n",
        "                shutil.rmtree(target)\n",
        "\n",
        "    materialize_split(train_df, \"train\", data_dir)\n",
        "    materialize_split(val_df, \"val\", data_dir)\n",
        "    materialize_split(test_df, \"test\", data_dir)\n",
        "    print_counts(data_dir)\n",
        "    print(\"[done] Data ready at:\", data_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdcx2xomaawN",
        "outputId": "f833920b-298d-45db-87fd-3e44b113bda7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[skip] Images already present under: /content/work/ham10000_extracted\n",
            "[skip] Images already present under: /content/work/ham10000_extracted\n",
            "[info] Found 10015 jpgs under /content/work/ham10000_extracted\n",
            "[info] Matched rows with metadata: 10015\n",
            "train: 100% 8012/8012 [00:15<00:00, 532.77img/s]\n",
            "  val: 100% 1001/1001 [00:02<00:00, 458.06img/s]\n",
            " test: 100% 1002/1002 [00:02<00:00, 373.37img/s]\n",
            "train {'akiec': 262, 'bkl': 879, 'bcc': 411, 'df': 92, 'mel': 890, 'nv': 5364, 'vasc': 114}\n",
            "val {'akiec': 33, 'bkl': 110, 'bcc': 51, 'df': 12, 'mel': 111, 'nv': 670, 'vasc': 14}\n",
            "test {'akiec': 32, 'bkl': 110, 'bcc': 52, 'df': 11, 'mel': 112, 'nv': 671, 'vasc': 14}\n",
            "[done] Data ready at: /content/work/data\n"
          ]
        }
      ],
      "source": [
        "!python /content/scripts/split_ham10000.py \\\n",
        "  --project_dir \"/content/work\" \\\n",
        "  --train 0.8 --val 0.1 --test 0.1 --seed 42 --clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5fOBxPRad-E",
        "outputId": "c73c98be-1e43-49f5-d9c8-bc0910dfe4d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train {'akiec': 262, 'bcc': 411, 'bkl': 879, 'df': 92, 'mel': 890, 'nv': 5364, 'vasc': 114}\n",
            "val {'akiec': 33, 'bcc': 51, 'bkl': 110, 'df': 12, 'mel': 111, 'nv': 670, 'vasc': 14}\n",
            "test {'akiec': 32, 'bcc': 52, 'bkl': 110, 'df': 11, 'mel': 112, 'nv': 671, 'vasc': 14}\n"
          ]
        }
      ],
      "source": [
        "#Quick sanity check:\n",
        "import os\n",
        "for split in (\"train\",\"val\",\"test\"):\n",
        "    base = os.path.join(\"/content/work/data\", split)\n",
        "    classes = [d for d in sorted(os.listdir(base)) if os.path.isdir(os.path.join(base,d))]\n",
        "    counts = {c: len(os.listdir(os.path.join(base,c))) for c in classes}\n",
        "    print(split, counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryto_ZVZ0ZSc",
        "outputId": "67a83590-dd99-4388-9f9f-407fcf58e6a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8012 files belonging to 7 classes.\n",
            "Found 1001 files belonging to 7 classes.\n",
            "Found 1002 files belonging to 7 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Epoch 1/2\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 162ms/step - accuracy: 0.2096 - loss: 2.5398 - val_accuracy: 0.4046 - val_loss: 1.5913\n",
            "Epoch 2/2\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 101ms/step - accuracy: 0.3635 - loss: 1.9432 - val_accuracy: 0.5115 - val_loss: 1.3363\n",
            "Epoch 1/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 162ms/step - accuracy: 0.4361 - loss: 1.5605 - val_accuracy: 0.5315 - val_loss: 1.2649\n",
            "Epoch 2/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 113ms/step - accuracy: 0.5037 - loss: 1.2779 - val_accuracy: 0.5664 - val_loss: 1.2020\n",
            "Epoch 3/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 110ms/step - accuracy: 0.5779 - loss: 1.0740 - val_accuracy: 0.5894 - val_loss: 1.1520\n",
            "Epoch 4/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.6173 - loss: 0.9374 - val_accuracy: 0.6154 - val_loss: 1.0818\n",
            "Epoch 5/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.6628 - loss: 0.8213 - val_accuracy: 0.6314 - val_loss: 1.0469\n",
            "Epoch 6/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 110ms/step - accuracy: 0.6944 - loss: 0.7229 - val_accuracy: 0.6474 - val_loss: 0.9985\n",
            "Epoch 7/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 112ms/step - accuracy: 0.7123 - loss: 0.6459 - val_accuracy: 0.6753 - val_loss: 0.9487\n",
            "Epoch 8/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 111ms/step - accuracy: 0.7529 - loss: 0.5627 - val_accuracy: 0.6793 - val_loss: 0.9318\n",
            "Epoch 9/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.7572 - loss: 0.5003 - val_accuracy: 0.6923 - val_loss: 0.9002\n",
            "Epoch 10/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 110ms/step - accuracy: 0.7829 - loss: 0.4472 - val_accuracy: 0.7113 - val_loss: 0.8564\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       akiec       0.60      0.47      0.53        32\n",
            "         bcc       0.58      0.48      0.53        52\n",
            "         bkl       0.51      0.69      0.59       110\n",
            "          df       0.21      0.55      0.31        11\n",
            "         mel       0.35      0.69      0.46       112\n",
            "          nv       0.96      0.75      0.85       671\n",
            "        vasc       1.00      0.64      0.78        14\n",
            "\n",
            "    accuracy                           0.71      1002\n",
            "   macro avg       0.60      0.61      0.58      1002\n",
            "weighted avg       0.80      0.71      0.74      1002\n",
            "\n",
            "Saved: runs/resnet50/colab_run\n",
            "[master] Appended summary to: runs/experiments_master.csv\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os, json, time, csv, datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "# =============================\n",
        "# CONFIG (edit this in Colab)\n",
        "# =============================\n",
        "class Args:\n",
        "    data = \"/content/work/data\"   # <-- your dataset folder with train/val/test\n",
        "    epochs = 10\n",
        "    warmup = 2\n",
        "    size = 224\n",
        "    batch = 32\n",
        "    base_lr = 1e-4\n",
        "    ft_lr = 1e-5\n",
        "    unfreeze = 10\n",
        "    binary = 0\n",
        "    run_name = \"colab_run\"\n",
        "    out_dir = \"runs\"\n",
        "\n",
        "args = Args()\n",
        "\n",
        "# =============================\n",
        "# Functions\n",
        "# =============================\n",
        "def get_datasets(data_dir, img_size=(224, 224), batch=32, seed=42, binary=False):\n",
        "    def loader(split, shuffle):\n",
        "        return tf.keras.utils.image_dataset_from_directory(\n",
        "            os.path.join(data_dir, split),\n",
        "            image_size=img_size, batch_size=batch, seed=seed, shuffle=shuffle\n",
        "        )\n",
        "    ds_train = loader(\"train\", True)\n",
        "    ds_val   = loader(\"val\",   False)\n",
        "    ds_test  = loader(\"test\",  False)\n",
        "    class_names = ds_train.class_names\n",
        "\n",
        "    aug = keras.Sequential([\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.05),\n",
        "        layers.RandomZoom(0.1),\n",
        "    ])\n",
        "    ds_train = ds_train.map(lambda x, y: (aug(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds_train = ds_train.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    ds_val   = ds_val.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    ds_test  = ds_test.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    return ds_train, ds_val, ds_test, class_names, bool(binary)\n",
        "\n",
        "def compute_class_weights(ds, num_classes):\n",
        "    counts = np.zeros(num_classes, dtype=np.int64)\n",
        "    for _, y in ds.unbatch():\n",
        "        counts[int(y.numpy())] += 1\n",
        "    total = counts.sum()\n",
        "    return {i: float(total / (num_classes * max(counts[i], 1))) for i in range(num_classes)}\n",
        "\n",
        "def build_model(num_classes, img_size=(224, 224), binary=False):\n",
        "    inp = keras.Input(shape=(*img_size, 3))\n",
        "    x = tf.keras.applications.resnet50.preprocess_input(inp)\n",
        "    base = tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\", input_tensor=x)\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\", dtype=\"float32\")(x) if binary \\\n",
        "          else layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
        "    return keras.Model(inp, out), base\n",
        "\n",
        "def compile_and_fit(model, train_ds, val_ds, *, loss, lr, epochs, class_weight, ckpt_path):\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=loss, metrics=[\"accuracy\"])\n",
        "    os.makedirs(os.path.dirname(ckpt_path), exist_ok=True)\n",
        "    cbs = [\n",
        "        keras.callbacks.ModelCheckpoint(ckpt_path, save_best_only=True, monitor=\"val_accuracy\", mode=\"max\"),\n",
        "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor=\"val_accuracy\", mode=\"max\"),\n",
        "    ]\n",
        "    hist = model.fit(train_ds, validation_data=val_ds, epochs=epochs,\n",
        "                     class_weight=class_weight, callbacks=cbs)\n",
        "    return {k: [float(v) for v in vals] for k, vals in hist.history.items()}\n",
        "\n",
        "def eval_save(model, ds_test, names, out_dir, binary=False):\n",
        "    y_true, y_pred = [], []\n",
        "    for x, y in ds_test:\n",
        "        p = model.predict(x, verbose=0)\n",
        "        yp = (p.reshape(-1) >= 0.5).astype(int) if binary else p.argmax(axis=1)\n",
        "        y_true += y.numpy().tolist(); y_pred += yp.tolist()\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    acc = float(accuracy_score(y_true, y_pred))\n",
        "    f1  = float(f1_score(y_true, y_pred, average=(\"binary\" if binary else \"macro\")))\n",
        "    rep = classification_report(y_true, y_pred, target_names=names)\n",
        "    cm  = confusion_matrix(y_true, y_pred).tolist()\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    json.dump({\"accuracy\": acc, \"macro_f1\": f1, \"confusion_matrix\": cm},\n",
        "              open(os.path.join(out_dir,\"metrics.json\"),\"w\"), indent=2)\n",
        "    open(os.path.join(out_dir,\"classification_report.txt\"),\"w\").write(rep)\n",
        "    json.dump(names, open(os.path.join(out_dir,\"classes.json\"),\"w\"), indent=2)\n",
        "    print(rep); print(\"Saved:\", out_dir)\n",
        "    return acc, f1\n",
        "\n",
        "def merge_histories(h1, h2):\n",
        "    out = {}\n",
        "    keys = set(h1.keys()) | set(h2.keys())\n",
        "    for k in keys:\n",
        "        out[k] = (h1.get(k, []) + h2.get(k, []))\n",
        "    return out\n",
        "\n",
        "def write_epoch_csv(history, path_csv):\n",
        "    rows = []\n",
        "    n = max(len(history.get(\"accuracy\", [])), len(history.get(\"loss\", [])))\n",
        "    for i in range(n):\n",
        "        rows.append({\n",
        "            \"epoch\": i+1,\n",
        "            \"accuracy\": history.get(\"accuracy\", [None]*n)[i],\n",
        "            \"loss\": history.get(\"loss\", [None]*n)[i],\n",
        "            \"val_accuracy\": history.get(\"val_accuracy\", [None]*n)[i],\n",
        "            \"val_loss\": history.get(\"val_loss\", [None]*n)[i],\n",
        "        })\n",
        "    import pandas as pd\n",
        "    pd.DataFrame(rows).to_csv(path_csv, index=False)\n",
        "\n",
        "def append_master_row(master_csv, row_dict):\n",
        "    headers = [\"timestamp\",\"run_name\",\"data\",\"img_size\",\"batch\",\"warmup\",\"epochs\",\"unfreeze\",\n",
        "               \"base_lr\",\"ft_lr\",\"binary\",\"best_val_acc\",\"best_val_loss\",\"test_acc\",\"test_macro_f1\"]\n",
        "    os.makedirs(os.path.dirname(master_csv), exist_ok=True)\n",
        "    file_exists = os.path.isfile(master_csv)\n",
        "    with open(master_csv, \"a\", newline=\"\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=headers)\n",
        "        if not file_exists:\n",
        "            w.writeheader()\n",
        "        w.writerow({k: row_dict.get(k) for k in headers})\n",
        "\n",
        "# =============================\n",
        "# MAIN\n",
        "# =============================\n",
        "def main(a):\n",
        "    run = a.run_name or time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    out_root = a.out_dir if a.out_dir else \"runs\"\n",
        "    out = os.path.join(out_root, \"resnet50\", run)\n",
        "    os.makedirs(out, exist_ok=True)\n",
        "\n",
        "    ds_tr, ds_va, ds_te, names, binary = get_datasets(a.data, (a.size, a.size), a.batch, binary=bool(a.binary))\n",
        "    ncls = 2 if binary else len(names)\n",
        "    class_weight = compute_class_weights(ds_tr, ncls)\n",
        "\n",
        "    model, base = build_model(ncls, (a.size, a.size), binary)\n",
        "    loss = \"binary_crossentropy\" if binary else keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "    # warmup\n",
        "    base.trainable = False\n",
        "    hist_warm = compile_and_fit(model, ds_tr, ds_va, loss=loss, lr=a.base_lr,\n",
        "                                epochs=max(1, a.warmup), class_weight=class_weight,\n",
        "                                ckpt_path=os.path.join(out, \"best.keras\"))\n",
        "\n",
        "    # fine-tune\n",
        "    base.trainable = True\n",
        "    if a.unfreeze > 0 and a.unfreeze < len(base.layers):\n",
        "        for l in base.layers[:-a.unfreeze]:\n",
        "            l.trainable = False\n",
        "    hist_ft = compile_and_fit(model, ds_tr, ds_va, loss=loss, lr=a.ft_lr,\n",
        "                              epochs=a.epochs, class_weight=class_weight,\n",
        "                              ckpt_path=os.path.join(out, \"best.keras\"))\n",
        "\n",
        "    # histories\n",
        "    history = merge_histories(hist_warm, hist_ft)\n",
        "    json.dump(history, open(os.path.join(out,\"history.json\"),\"w\"), indent=2)\n",
        "    write_epoch_csv(history, os.path.join(out,\"history_epoch.csv\"))\n",
        "\n",
        "    # evaluate\n",
        "    test_acc, test_f1 = eval_save(model, ds_te, names, out, binary)\n",
        "\n",
        "    # master CSV\n",
        "    master_csv = os.path.join(out_root, \"experiments_master.csv\")\n",
        "    best_idx = int(np.nanargmax(history.get(\"val_accuracy\", [np.nan])))\n",
        "    best_val_acc  = float(history[\"val_accuracy\"][best_idx]) if \"val_accuracy\" in history else None\n",
        "    best_val_loss = float(history[\"val_loss\"][best_idx]) if \"val_loss\" in history else None\n",
        "\n",
        "    append_master_row(master_csv, {\n",
        "        \"timestamp\": datetime.datetime.now().isoformat(timespec=\"seconds\"),\n",
        "        \"run_name\": run,\n",
        "        \"data\": a.data,\n",
        "        \"img_size\": a.size,\n",
        "        \"batch\": a.batch,\n",
        "        \"warmup\": a.warmup,\n",
        "        \"epochs\": a.epochs,\n",
        "        \"unfreeze\": a.unfreeze,\n",
        "        \"base_lr\": a.base_lr,\n",
        "        \"ft_lr\": a.ft_lr,\n",
        "        \"binary\": int(a.binary),\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "        \"best_val_loss\": best_val_loss,\n",
        "        \"test_acc\": test_acc,\n",
        "        \"test_macro_f1\": test_f1,\n",
        "    })\n",
        "    print(f\"[master] Appended summary to: {master_csv}\")\n",
        "\n",
        "# =============================\n",
        "# RUN\n",
        "# =============================\n",
        "main(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9ADlRFE0v-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "053027b2-d3b8-4c24-9459-40575989b6dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists: True\n",
            "Splits: ['train', 'val', 'test']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Exists:\", os.path.isdir(\"/content/work/data\"))\n",
        "print(\"Splits:\", os.listdir(\"/content/work/data\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure the folder exists\n",
        "!mkdir -p /content/members"
      ],
      "metadata": {
        "id": "eTUMX_6x3ysG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/members/run_resnet50.py\n",
        "#!/usr/bin/env python3\n",
        "import os, json, time, argparse, csv, datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "MODEL_DIR = \"resnet50\"  # model-specific folder & master CSV\n",
        "\n",
        "def get_datasets(data_dir, img_size=(224,224), batch=32, seed=42, binary=False):\n",
        "    def loader(split, shuffle):\n",
        "        return tf.keras.utils.image_dataset_from_directory(\n",
        "            os.path.join(data_dir, split),\n",
        "            image_size=img_size, batch_size=batch, seed=seed, shuffle=shuffle\n",
        "        )\n",
        "    ds_train = loader(\"train\", True)\n",
        "    ds_val   = loader(\"val\",   False)\n",
        "    ds_test  = loader(\"test\",  False)\n",
        "    class_names = ds_train.class_names\n",
        "\n",
        "    aug = keras.Sequential([\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.05),\n",
        "        layers.RandomZoom(0.1),\n",
        "        layers.RandomContrast(0.1),\n",
        "    ])\n",
        "    ds_train = ds_train.map(lambda x,y:(aug(x),y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds_train = ds_train.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    ds_val   = ds_val.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    ds_test  = ds_test.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    return ds_train, ds_val, ds_test, class_names, bool(binary)\n",
        "\n",
        "def compute_class_weights(ds, n_classes):\n",
        "    counts = np.zeros(n_classes, dtype=np.int64)\n",
        "    for _, y in ds.unbatch():\n",
        "        counts[int(y.numpy())] += 1\n",
        "    tot = counts.sum()\n",
        "    return {i: float(tot / (n_classes * max(counts[i], 1))) for i in range(n_classes)}\n",
        "\n",
        "def build_model(num_classes, img_size=(224,224), binary=False):\n",
        "    from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "    inp = keras.Input(shape=(*img_size,3))\n",
        "    x = preprocess_input(inp)\n",
        "    base = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=x)\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\", dtype=\"float32\")(x) if binary \\\n",
        "          else layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
        "    return keras.Model(inp, out), base\n",
        "\n",
        "def compile_and_fit(model, train_ds, val_ds, *, loss, lr, epochs, class_weight, ckpt_path):\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss=loss, metrics=[\"accuracy\"])\n",
        "    os.makedirs(os.path.dirname(ckpt_path), exist_ok=True)\n",
        "    cbs = [\n",
        "        keras.callbacks.ModelCheckpoint(ckpt_path, save_best_only=True,\n",
        "                                        monitor=\"val_accuracy\", mode=\"max\"),\n",
        "        keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True,\n",
        "                                      monitor=\"val_accuracy\", mode=\"max\"),\n",
        "        keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3,\n",
        "                                          patience=2, min_lr=1e-6, verbose=1),\n",
        "    ]\n",
        "    hist = model.fit(train_ds, validation_data=val_ds, epochs=epochs,\n",
        "                     class_weight=class_weight, callbacks=cbs)\n",
        "    return {k: [float(v) for v in vals] for k, vals in hist.history.items()}\n",
        "\n",
        "def eval_save(model, ds_test, names, out_dir, binary=False):\n",
        "    y_true, y_pred = [], []\n",
        "    for x, y in ds_test:\n",
        "        p = model.predict(x, verbose=0)\n",
        "        yp = (p.reshape(-1) >= 0.5).astype(int) if binary else p.argmax(axis=1)\n",
        "        y_true += y.numpy().tolist(); y_pred += yp.tolist()\n",
        "    y_true = np.array(y_true); y_pred = np.array(y_pred)\n",
        "\n",
        "    acc = float(accuracy_score(y_true, y_pred))\n",
        "    f1  = float(f1_score(y_true, y_pred, average=(\"binary\" if binary else \"macro\")))\n",
        "    rep = classification_report(y_true, y_pred, target_names=names)\n",
        "    cm  = confusion_matrix(y_true, y_pred).tolist()\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    json.dump({\"accuracy\": acc, \"macro_f1\": f1, \"confusion_matrix\": cm},\n",
        "              open(os.path.join(out_dir,\"metrics.json\"),\"w\"), indent=2)\n",
        "    open(os.path.join(out_dir,\"classification_report.txt\"),\"w\").write(rep)\n",
        "    json.dump(names, open(os.path.join(out_dir,\"classes.json\"),\"w\"), indent=2)\n",
        "    print(rep); print(\"Saved:\", out_dir)\n",
        "    return acc, f1\n",
        "\n",
        "def write_epoch_csv(history, path_csv):\n",
        "    import pandas as pd\n",
        "    n = max(len(history.get(\"accuracy\",[])), len(history.get(\"loss\",[])))\n",
        "    rows = [{\n",
        "        \"epoch\": i+1,\n",
        "        \"accuracy\": history.get(\"accuracy\",[None]*n)[i],\n",
        "        \"loss\": history.get(\"loss\",[None]*n)[i],\n",
        "        \"val_accuracy\": history.get(\"val_accuracy\",[None]*n)[i],\n",
        "        \"val_loss\": history.get(\"val_loss\",[None]*n)[i],\n",
        "    } for i in range(n)]\n",
        "    pd.DataFrame(rows).to_csv(path_csv, index=False)\n",
        "\n",
        "def append_master_row(master_csv, row):\n",
        "    headers = [\"timestamp\",\"run_name\",\"data\",\"img_size\",\"batch\",\"warmup\",\"epochs\",\n",
        "               \"unfreeze\",\"base_lr\",\"ft_lr\",\"binary\",\"best_val_acc\",\"best_val_loss\",\n",
        "               \"test_acc\",\"test_macro_f1\"]\n",
        "    os.makedirs(os.path.dirname(master_csv), exist_ok=True)\n",
        "    new = not os.path.isfile(master_csv)\n",
        "    with open(master_csv, \"a\", newline=\"\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=headers)\n",
        "        if new: w.writeheader()\n",
        "        w.writerow({k: row.get(k) for k in headers})\n",
        "\n",
        "def main(a):\n",
        "    run = a.run_name or time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    out_root = a.out_dir or \"runs\"\n",
        "    model_root = os.path.join(out_root, MODEL_DIR)\n",
        "    out = os.path.join(model_root, run)\n",
        "    os.makedirs(out, exist_ok=True)\n",
        "\n",
        "    ds_tr, ds_va, ds_te, names, binary = get_datasets(a.data, (a.size, a.size), a.batch, binary=bool(a.binary))\n",
        "    ncls = 2 if binary else len(names)\n",
        "    class_weight = compute_class_weights(ds_tr, ncls)\n",
        "\n",
        "    model, base = build_model(ncls, (a.size, a.size), binary)\n",
        "    loss = \"binary_crossentropy\" if binary else keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "    # Phase 1: warmup (base frozen)\n",
        "    base.trainable = False\n",
        "    hist_warm = compile_and_fit(model, ds_tr, ds_va, loss=loss, lr=a.base_lr,\n",
        "                                epochs=max(1, a.warmup), class_weight=class_weight,\n",
        "                                ckpt_path=os.path.join(out, \"best.keras\"))\n",
        "\n",
        "    # Phase 2: fine-tune (partial unfreeze)\n",
        "    base.trainable = True\n",
        "    if a.unfreeze > 0 and a.unfreeze < len(base.layers):\n",
        "        for l in base.layers[:-a.unfreeze]:\n",
        "            l.trainable = False\n",
        "    hist_ft = compile_and_fit(model, ds_tr, ds_va, loss=loss, lr=a.ft_lr,\n",
        "                              epochs=a.epochs, class_weight=class_weight,\n",
        "                              ckpt_path=os.path.join(out, \"best.keras\"))\n",
        "\n",
        "    # Save histories\n",
        "    history = {}\n",
        "    for k in set(list(hist_warm.keys()) + list(hist_ft.keys())):\n",
        "        history[k] = (hist_warm.get(k, []) + hist_ft.get(k, []))\n",
        "    json.dump(history, open(os.path.join(out,\"history.json\"),\"w\"), indent=2)\n",
        "    write_epoch_csv(history, os.path.join(out,\"history_epoch.csv\"))\n",
        "\n",
        "    # Evaluate & save reports\n",
        "    test_acc, test_f1 = eval_save(model, ds_te, names, out, binary)\n",
        "\n",
        "    # Model-specific master CSV\n",
        "    best_idx = int(np.nanargmax(history.get(\"val_accuracy\", [np.nan])))\n",
        "    best_val_acc  = float(history[\"val_accuracy\"][best_idx]) if \"val_accuracy\" in history else None\n",
        "    best_val_loss = float(history[\"val_loss\"][best_idx]) if \"val_loss\" in history else None\n",
        "    master_csv = os.path.join(model_root, \"experiments_master.csv\")\n",
        "    append_master_row(master_csv, {\n",
        "        \"timestamp\": datetime.datetime.now().isoformat(timespec=\"seconds\"),\n",
        "        \"run_name\": run,\n",
        "        \"data\": a.data, \"img_size\": a.size, \"batch\": a.batch,\n",
        "        \"warmup\": a.warmup, \"epochs\": a.epochs, \"unfreeze\": a.unfreeze,\n",
        "        \"base_lr\": a.base_lr, \"ft_lr\": a.ft_lr, \"binary\": int(a.binary),\n",
        "        \"best_val_acc\": best_val_acc, \"best_val_loss\": best_val_loss,\n",
        "        \"test_acc\": test_acc, \"test_macro_f1\": test_f1\n",
        "    })\n",
        "    print(f\"[master] Appended summary to: {master_csv}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ap = argparse.ArgumentParser()\n",
        "    # default so you don't hit the --data error\n",
        "    ap.add_argument(\"--data\", default=os.environ.get(\"DATA_DIR\", \"/content/work/data\"))\n",
        "    ap.add_argument(\"--epochs\", type=int, default=20)\n",
        "    ap.add_argument(\"--warmup\", type=int, default=3)\n",
        "    ap.add_argument(\"--size\", type=int, default=224)\n",
        "    ap.add_argument(\"--batch\", type=int, default=32)\n",
        "    ap.add_argument(\"--base_lr\", type=float, default=1e-4)\n",
        "    ap.add_argument(\"--ft_lr\", type=float, default=1e-5)\n",
        "    ap.add_argument(\"--unfreeze\", type=int, default=20)  # unfreeze tail layers\n",
        "    ap.add_argument(\"--binary\", type=int, default=0)\n",
        "    ap.add_argument(\"--run_name\", default=\"\")\n",
        "    ap.add_argument(\"--out_dir\", default=\"runs\")\n",
        "    a = ap.parse_args(); main(a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE6KrY5e21xQ",
        "outputId": "7643e403-4975-4199-94c4-55bd0d3a875d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/members/run_resnet50.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIlzypPnwLjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6424a477-fe16-4c97-ca28-f8a7b2563b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-08 07:39:28.864567: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759909168.886028    8635 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759909168.892135    8635 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759909168.907757    8635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759909168.907780    8635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759909168.907784    8635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759909168.907789    8635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-08 07:39:28.912351: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Found 8012 files belonging to 7 classes.\n",
            "2025-10-08 07:39:33.128129: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1759909173.128283    8635 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Found 1001 files belonging to 7 classes.\n",
            "Found 1002 files belonging to 7 classes.\n",
            "2025-10-08 07:41:38.202863: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "Epoch 1/3\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1759909307.052221    8675 service.cc:152] XLA service 0x7b332c002b00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1759909307.052266    8675 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-10-08 07:41:47.406422: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1759909309.122721    8675 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2025-10-08 07:41:50.815978: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[32,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,56,56]{3,2,1,0} %bitcast.7409, f32[64,64,3,3]{3,2,1,0} %bitcast.7416, f32[64]{0} %bitcast.7418), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-08 07:41:51.303992: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[32,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,28,28]{3,2,1,0} %bitcast.7814, f32[128,128,3,3]{3,2,1,0} %bitcast.7821, f32[128]{0} %bitcast.7823), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-08 07:41:51.820401: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[32,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,14,14]{3,2,1,0} %bitcast.8342, f32[256,256,3,3]{3,2,1,0} %bitcast.8349, f32[256]{0} %bitcast.8351), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-08 07:41:52.295159: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[32,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,7,7]{3,2,1,0} %bitcast.9116, f32[512,512,3,3]{3,2,1,0} %bitcast.9123, f32[512]{0} %bitcast.9125), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "I0000 00:00:1759909314.560096    8675 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m250/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2244 - loss: 2.60032025-10-08 07:42:17.875324: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[12,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,64,56,56]{3,2,1,0} %bitcast.7409, f32[64,64,3,3]{3,2,1,0} %bitcast.7416, f32[64]{0} %bitcast.7418), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-08 07:42:18.136369: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[12,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,128,28,28]{3,2,1,0} %bitcast.7814, f32[128,128,3,3]{3,2,1,0} %bitcast.7821, f32[128]{0} %bitcast.7823), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-08 07:42:18.377553: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[12,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,256,14,14]{3,2,1,0} %bitcast.8342, f32[256,256,3,3]{3,2,1,0} %bitcast.8349, f32[256]{0} %bitcast.8351), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-08 07:42:18.641651: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[12,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,512,7,7]{3,2,1,0} %bitcast.9116, f32[512,512,3,3]{3,2,1,0} %bitcast.9123, f32[512]{0} %bitcast.9125), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.2245 - loss: 2.59892025-10-08 07:42:31.667167: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[9,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,64,56,56]{3,2,1,0} %bitcast.4851, f32[64,64,3,3]{3,2,1,0} %bitcast.4858, f32[64]{0} %bitcast.4860), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-08 07:42:31.883328: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[9,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,128,28,28]{3,2,1,0} %bitcast.5256, f32[128,128,3,3]{3,2,1,0} %bitcast.5263, f32[128]{0} %bitcast.5265), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-08 07:42:32.086470: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[9,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,256,14,14]{3,2,1,0} %bitcast.5784, f32[256,256,3,3]{3,2,1,0} %bitcast.5791, f32[256]{0} %bitcast.5793), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-08 07:42:32.293811: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[9,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,512,7,7]{3,2,1,0} %bitcast.6558, f32[512,512,3,3]{3,2,1,0} %bitcast.6565, f32[512]{0} %bitcast.6567), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 161ms/step - accuracy: 0.2246 - loss: 2.5976 - val_accuracy: 0.4585 - val_loss: 1.4764 - learning_rate: 1.0000e-04\n",
            "Epoch 2/3\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 101ms/step - accuracy: 0.3584 - loss: 1.9078 - val_accuracy: 0.5155 - val_loss: 1.2888 - learning_rate: 1.0000e-04\n",
            "Epoch 3/3\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - accuracy: 0.4242 - loss: 1.6674 - val_accuracy: 0.5345 - val_loss: 1.2123 - learning_rate: 1.0000e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 156ms/step - accuracy: 0.4978 - loss: 1.4353 - val_accuracy: 0.6084 - val_loss: 1.0790 - learning_rate: 1.0000e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 110ms/step - accuracy: 0.5440 - loss: 1.1643 - val_accuracy: 0.6094 - val_loss: 1.0551 - learning_rate: 1.0000e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.5876 - loss: 1.0364 - val_accuracy: 0.6204 - val_loss: 1.0111 - learning_rate: 1.0000e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 108ms/step - accuracy: 0.6313 - loss: 0.8915 - val_accuracy: 0.6364 - val_loss: 0.9747 - learning_rate: 1.0000e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 108ms/step - accuracy: 0.6656 - loss: 0.7788 - val_accuracy: 0.6523 - val_loss: 0.9222 - learning_rate: 1.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.6947 - loss: 0.7025 - val_accuracy: 0.6723 - val_loss: 0.8872 - learning_rate: 1.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.7201 - loss: 0.6005 - val_accuracy: 0.6923 - val_loss: 0.8429 - learning_rate: 1.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.7443 - loss: 0.5565 - val_accuracy: 0.7053 - val_loss: 0.8219 - learning_rate: 1.0000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 108ms/step - accuracy: 0.7705 - loss: 0.4820 - val_accuracy: 0.7103 - val_loss: 0.8124 - learning_rate: 1.0000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 108ms/step - accuracy: 0.7840 - loss: 0.4285 - val_accuracy: 0.7253 - val_loss: 0.7813 - learning_rate: 1.0000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.8018 - loss: 0.3822 - val_accuracy: 0.7353 - val_loss: 0.7567 - learning_rate: 1.0000e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 110ms/step - accuracy: 0.8248 - loss: 0.3245 - val_accuracy: 0.7433 - val_loss: 0.7431 - learning_rate: 1.0000e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.8369 - loss: 0.2910 - val_accuracy: 0.7532 - val_loss: 0.7342 - learning_rate: 1.0000e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 104ms/step - accuracy: 0.8537 - loss: 0.2564 - val_accuracy: 0.7493 - val_loss: 0.7340 - learning_rate: 1.0000e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 108ms/step - accuracy: 0.8671 - loss: 0.2247 - val_accuracy: 0.7622 - val_loss: 0.7177 - learning_rate: 1.0000e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.8807 - loss: 0.1956 - val_accuracy: 0.7752 - val_loss: 0.6903 - learning_rate: 1.0000e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.8906 - loss: 0.1795 - val_accuracy: 0.7892 - val_loss: 0.6749 - learning_rate: 1.0000e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.8994 - loss: 0.1581 - val_accuracy: 0.7932 - val_loss: 0.6925 - learning_rate: 1.0000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 104ms/step - accuracy: 0.9136 - loss: 0.1355 - val_accuracy: 0.7912 - val_loss: 0.6590 - learning_rate: 1.0000e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 109ms/step - accuracy: 0.9196 - loss: 0.1191 - val_accuracy: 0.7972 - val_loss: 0.6556 - learning_rate: 1.0000e-05\n",
            "2025-10-08 07:53:44.615225: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[10,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,64,56,56]{3,2,1,0} %bitcast.4540, f32[64,64,3,3]{3,2,1,0} %bitcast.4547, f32[64]{0} %bitcast.4549), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-08 07:53:44.859004: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[10,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,128,28,28]{3,2,1,0} %bitcast.4945, f32[128,128,3,3]{3,2,1,0} %bitcast.4952, f32[128]{0} %bitcast.4954), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-08 07:53:45.075434: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[10,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,256,14,14]{3,2,1,0} %bitcast.5473, f32[256,256,3,3]{3,2,1,0} %bitcast.5480, f32[256]{0} %bitcast.5482), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-08 07:53:45.291931: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[10,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[10,512,7,7]{3,2,1,0} %bitcast.6247, f32[512,512,3,3]{3,2,1,0} %bitcast.6254, f32[512]{0} %bitcast.6256), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-10-08 07:53:46.717892: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       akiec       0.59      0.50      0.54        32\n",
            "         bcc       0.69      0.48      0.57        52\n",
            "         bkl       0.59      0.75      0.66       110\n",
            "          df       0.33      0.45      0.38        11\n",
            "         mel       0.47      0.74      0.58       112\n",
            "          nv       0.95      0.85      0.89       671\n",
            "        vasc       1.00      0.64      0.78        14\n",
            "\n",
            "    accuracy                           0.79      1002\n",
            "   macro avg       0.66      0.63      0.63      1002\n",
            "weighted avg       0.82      0.79      0.80      1002\n",
            "\n",
            "Saved: /content/runs/resnet50/e20_b32\n",
            "[master] Appended summary to: /content/runs/resnet50/experiments_master.csv\n"
          ]
        }
      ],
      "source": [
        "# run 1\n",
        "!python /content/members/run_resnet50.py \\\n",
        "  --data \"/content/work/data\" \\\n",
        "  --epochs 20 --warmup 3 --unfreeze 10 \\\n",
        "  --batch 32 --base_lr 1e-4 --ft_lr 1e-5 \\\n",
        "  --out_dir /content/runs --run_name e20_b32\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run 2 (fewer epochs, larger batch — tests faster convergence)\n",
        "!python /content/members/run_resnet50.py \\\n",
        "  --data \"/content/work/data\" \\\n",
        "  --epochs 15 --warmup 2 --unfreeze 10 \\\n",
        "  --batch 64 --base_lr 1e-4 --ft_lr 1e-5 \\\n",
        "  --out_dir /content/runs --run_name e15_b64"
      ],
      "metadata": {
        "id": "3YliC6IT5Ady"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run 3\n",
        "!python /content/members/run_resnet50.py \\\n",
        "  --data \"/content/work/data\" \\\n",
        "  --epochs 40 --warmup 3 --unfreeze 10 \\\n",
        "  --batch 16 --base_lr 1e-4 --ft_lr 1e-5 \\\n",
        "  --out_dir /content/runs --run_name e40_b16"
      ],
      "metadata": {
        "id": "K8OCH16UwSUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run 4 (higher learning rate for fine-tune)\n",
        "!python /content/members/run_resnet50.py \\\n",
        "  --data \"/content/work/data\" \\\n",
        "  --epochs 25 --warmup 3 --unfreeze 10 \\\n",
        "  --batch 32 --base_lr 1e-4 --ft_lr 5e-5 \\\n",
        "  --out_dir /content/runs --run_name e25_b32_ftlr5e5"
      ],
      "metadata": {
        "id": "G1eLimNNw2XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run 5 (more fine-tuning, unfreeze 30 layers)\n",
        "!python /content/members/run_resnet50.py \\\n",
        "  --data \"/content/work/data\" \\\n",
        "  --epochs 30 --warmup 3 --unfreeze 30 \\\n",
        "  --batch 32 --base_lr 5e-5 --ft_lr 1e-5 \\\n",
        "  --out_dir /content/runs --run_name e30_b32_unf30"
      ],
      "metadata": {
        "id": "2bDn2MBCw90m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run 6 (very small batch, stress test on gradients)\n",
        "!python /content/members/run_resnet50.py \\\n",
        "  --data \"/content/work/data\" \\\n",
        "  --epochs 25 --warmup 3 --unfreeze 10 \\\n",
        "  --batch 8 --base_lr 1e-4 --ft_lr 1e-5 \\\n",
        "  --out_dir /content/runs --run_name e25_b8"
      ],
      "metadata": {
        "id": "1XV4eYtzxDH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify per-run files\n",
        "!ls -lah /content/runs/resnet50/e20_b32\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-R3f_2v4iLe",
        "outputId": "2c4d55f1-3399-4a0e-bf39-33361612eb4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 125M\n",
            "drwxr-xr-x 2 root root 4.0K Oct  8 07:53 .\n",
            "drwxr-xr-x 5 root root 4.0K Oct  8 07:53 ..\n",
            "-rw-r--r-- 1 root root 125M Oct  8 07:53 best.keras\n",
            "-rw-r--r-- 1 root root   66 Oct  8 07:53 classes.json\n",
            "-rw-r--r-- 1 root root  596 Oct  8 07:53 classification_report.txt\n",
            "-rw-r--r-- 1 root root 1.8K Oct  8 07:53 history_epoch.csv\n",
            "-rw-r--r-- 1 root root 2.9K Oct  8 07:53 history.json\n",
            "-rw-r--r-- 1 root root  635 Oct  8 07:53 metrics.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Master CSV (all runs + scores)\n",
        "!sed -n '1,10p' /content/runs/experiments_master.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USOH5j-q4l3p",
        "outputId": "ae529a4c-0bd0-4f26-c1af-65252a142cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timestamp,run_name,data,img_size,batch,warmup,epochs,unfreeze,base_lr,ft_lr,binary,best_val_acc,best_val_loss,test_acc,test_macro_f1\r\n",
            "2025-10-08T07:26:54,colab_run,/content/work/data,224,32,2,10,10,0.0001,1e-05,0,0.7112886905670166,0.8564485907554626,0.7125748502994012,0.5767469017658539\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b0a82a-20ab-4223-e046-2047620992d2",
        "id": "Jx4SC8LxqACg"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        261.84M 100%  163.63MB/s    0:00:01 (xfr#14, to-chk=0/19)\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/EfficientNet/efficientnet/experiments_master.csv\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/DenseNet/densenet121/experiments_master.csv\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/MobileNet/mobilenetv2/experiments_master.csv\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/resnet50/experiments_master.csv\n",
            "/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50/experiments_master.csv\n"
          ]
        }
      ],
      "source": [
        "#Save results back to Drive (persistent)\n",
        "\n",
        "# Save all runs\n",
        "!mkdir -p \"/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50\"\n",
        "!rsync -ah --info=progress2 \"/content/runs/\" \"/content/drive/MyDrive/SKIN_CANCER_RESULTS/resnet50\"\n",
        "\n",
        "# Inspect what's saved\n",
        "!find \"/content/drive/MyDrive/SKIN_CANCER_RESULTS\" -maxdepth 3 -type f | head -n 20"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}